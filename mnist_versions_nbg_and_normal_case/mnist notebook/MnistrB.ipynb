{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from nni.algorithms.compression.pytorch.quantization import LsqQuantizer, QAT_Quantizer\n",
    "\n",
    "import torch.nn as nn\n",
    "import onnx\n",
    "import onnx.numpy_helper\n",
    "\n",
    "### markus\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "# choose the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Dataloader for MNIST Dataset\n",
    "\n",
    "## convert images from 1-color channel to 3-color channel images\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,)), transforms.Lambda(lambda x: x.repeat(3, 1, 1) )])\n",
    "\n",
    "root='data'\n",
    "# if not exist, download mnist dataset\n",
    "train_set = datasets.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = datasets.MNIST(root=root, train=False, transform=trans, download=True)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export and view image to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 : (3, 28, 28) -> (28, 28, 3)\n",
      "0 : (3, 28, 28) -> (28, 28, 3)\n",
      "4 : (3, 28, 28) -> (28, 28, 3)\n",
      "1 : (3, 28, 28) -> (28, 28, 3)\n",
      "9 : (3, 28, 28) -> (28, 28, 3)\n",
      "2 : (3, 28, 28) -> (28, 28, 3)\n",
      "3 : (3, 28, 28) -> (28, 28, 3)\n",
      "6 : (3, 28, 28) -> (28, 28, 3)\n",
      "7 : (3, 28, 28) -> (28, 28, 3)\n",
      "8 : (3, 28, 28) -> (28, 28, 3)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute('style', 'box-sizing: content-box;');\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            canvas.setAttribute(\n                'style',\n                'width: ' + width + 'px; height: ' + height + 'px;'\n            );\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        return function (event) {\n            return fig.mouse_event(event, name);\n        };\n    }\n\n    rubberband_canvas.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    rubberband_canvas.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband_canvas.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    rubberband_canvas.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.rubberband_canvas.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\n// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function (e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e) {\n        e = window.event;\n    }\n    if (e.target) {\n        targ = e.target;\n    } else if (e.srcElement) {\n        targ = e.srcElement;\n    }\n    if (targ.nodeType === 3) {\n        // defeat Safari bug\n        targ = targ.parentNode;\n    }\n\n    // pageX,Y are the mouse positions relative to the document\n    var boundingRect = targ.getBoundingClientRect();\n    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n\n    return { x: x, y: y };\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    var canvas_pos = mpl.findpos(event);\n\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * this.ratio;\n    var y = canvas_pos.y * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        guiEvent: simpleKeys(event),\n    });\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='6de799de-4447-48cb-839b-f8c5d46b187e'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7feb15b4a910>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = set()\n",
    "for i in range(0,100):\n",
    "    image, label = train_set[i]\n",
    "\n",
    "    # export until all numbers are present\n",
    "    if len(numbers)==10:\n",
    "        break\n",
    "    if label not in numbers:\n",
    "        numbers.add(label)\n",
    "        # denormalize\n",
    "        imag=(np.array(image.tolist())+0.5) * 255\n",
    "        # shape image from CHW [RRRRR[..],GGG[...],BBB[...]] -> HWC (3x28x28  -> 28x28x3 [RGB,RGB,RGB,RGB,...])\n",
    "        imag_tp = np.ascontiguousarray( imag.transpose((1,2,0)), dtype=np.uint8)\n",
    "        print(f\"{label} : {imag.shape} -> {imag_tp.shape}\")\n",
    "       \n",
    "        #print(imag.shape)\n",
    "        #print(imag.astype(np.uint8))\n",
    "        pil_image = PIL.Image.frombytes('RGB',(28,28), imag_tp)\n",
    "        pil_image.save(\"example_images_rgb\\\\\"+str(label)+\".bmp\")\n",
    "        \n",
    "        \n",
    "# visualize the last image as example\n",
    "plt.imshow(imag_tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "         -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "         -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "         -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "        [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "         -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "         -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "         -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "        [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "         -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "         -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "         -0.5000, -0.5000, -0.5000, -0.5000]])\n",
      "[[-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.45882353  0.29803922  0.4        -0.37647059 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.4        -0.31764706 -0.31764706\n",
      "  -0.38431373 -0.1254902   0.49803922  0.34509804 -0.45098039 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.3254902\n",
      "   0.10588235  0.22745098  0.22745098  0.37647059  0.49411765  0.49411765\n",
      "   0.02352941  0.18823529  0.50196078  0.23921569 -0.42745098 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.06666667\n",
      "   0.49411765  0.49411765  0.49411765  0.46666667  0.13333333  0.39607843\n",
      "   0.49411765  0.49411765  0.49803922 -0.1372549  -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922  0.00392157  0.4627451\n",
      "   0.49411765  0.12156863  0.03921569 -0.41960784 -0.49803922 -0.31372549\n",
      "   0.41568627  0.49411765  0.41568627 -0.47058824 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922  0.04705882  0.49803922\n",
      "   0.37647059 -0.40392157 -0.49803922 -0.49803922 -0.36078431  0.16862745\n",
      "   0.49803922  0.45882353 -0.08235294 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.28627451  0.33333333\n",
      "   0.49411765  0.13333333 -0.45882353 -0.4         0.2         0.49411765\n",
      "   0.42745098 -0.05490196 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.4745098   0.10980392\n",
      "   0.49411765  0.39607843 -0.18431373  0.37647059  0.49411765  0.49411765\n",
      "  -0.07058824 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922  0.05490196\n",
      "   0.49411765  0.49411765  0.49411765  0.49803922  0.49411765  0.10588235\n",
      "  -0.38823529 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.06666667\n",
      "   0.49411765  0.49411765  0.49411765  0.49803922  0.20392157 -0.35294118\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49019608  0.17254902\n",
      "   0.49803922  0.49803922  0.49803922  0.20392157 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922  0.17254902  0.49411765\n",
      "   0.49411765  0.49411765  0.49411765  0.2        -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.4        -0.01568627  0.49803922  0.49411765\n",
      "   0.29803922  0.11372549  0.49411765  0.28627451 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.13333333  0.49411765  0.49803922 -0.02352941\n",
      "  -0.45098039 -0.13333333  0.49411765  0.12156863 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.24705882  0.43921569  0.49411765 -0.2        -0.47058824\n",
      "  -0.37647059  0.36078431  0.49411765 -0.00392157 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922  0.02352941  0.49803922  0.25098039 -0.49803922 -0.48235294\n",
      "  -0.0745098   0.41960784  0.49803922 -0.08235294 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922  0.01960784  0.49411765  0.24705882 -0.48235294 -0.16470588\n",
      "   0.49411765  0.42745098  0.10588235 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922  0.10196078  0.49411765  0.16470588  0.25490196  0.49411765\n",
      "   0.49411765 -0.19607843 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.05882353  0.49411765  0.49411765  0.49803922  0.42745098\n",
      "   0.00784314 -0.46666667 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.43529412 -0.03529412  0.45490196  0.25098039 -0.05490196\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]\n",
      " [-0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922 -0.49803922\n",
      "  -0.49803922 -0.49803922 -0.49803922 -0.49803922]]\n"
     ]
    }
   ],
   "source": [
    "print(image[:,:,0])\n",
    "print( (imag_tp[:,:, 0].astype(float)-127) / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the normal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: https://karanbirchahal.medium.com/how-to-quantise-an-mnist-network-to-8-bits-in-pytorch-no-retraining-required-from-scratch-39f634ac8459\n",
    "## we want true rgb data to be trained\n",
    "mnist = False\n",
    "if mnist:\n",
    "  num_channels = 1\n",
    "else:\n",
    "  num_channels = 3\n",
    "\n",
    "class Mnist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mnist, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5, 1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(20, 50, 1, 1)\n",
    "        ########################\n",
    "        self.conv4 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv5 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv6 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv7 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv8 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv9 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv10 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv11 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv12 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv13 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv14 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv15 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv16 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv17 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv18 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv19 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv20 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv21 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv22 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv23 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv24 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv25 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv26 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv27 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv28 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv29 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv30 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv31 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv32 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv33 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv34 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv35 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv36 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv37 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv38 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv39 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv40 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv41 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv42 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv43 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv44 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv45 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv46 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv47 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv48 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv49 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv50 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv51 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv52 = nn.Conv2d(50, 50, 1, 1)\n",
    "        self.conv53 = nn.Conv2d(50, 50, 1, 1)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        ########################\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = F.relu(self.conv10(x))\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv12(x))\n",
    "        x = F.relu(self.conv13(x))\n",
    "        x = F.relu(self.conv14(x))\n",
    "        x = F.relu(self.conv15(x))\n",
    "        x = F.relu(self.conv16(x))\n",
    "        x = F.relu(self.conv17(x))\n",
    "        x = F.relu(self.conv18(x))\n",
    "        x = F.relu(self.conv19(x))\n",
    "        x = F.relu(self.conv20(x))\n",
    "        x = F.relu(self.conv21(x))\n",
    "        x = F.relu(self.conv22(x))\n",
    "        x = F.relu(self.conv23(x))\n",
    "        x = F.relu(self.conv24(x))\n",
    "        x = F.relu(self.conv25(x))\n",
    "        x = F.relu(self.conv26(x))\n",
    "        x = F.relu(self.conv27(x))\n",
    "        x = F.relu(self.conv28(x))\n",
    "        x = F.relu(self.conv29(x))\n",
    "        x = F.relu(self.conv30(x))\n",
    "        x = F.relu(self.conv31(x))\n",
    "        x = F.relu(self.conv32(x))\n",
    "        x = F.relu(self.conv33(x))\n",
    "        x = F.relu(self.conv34(x))\n",
    "        x = F.relu(self.conv35(x))\n",
    "        x = F.relu(self.conv36(x))\n",
    "        x = F.relu(self.conv37(x))\n",
    "        x = F.relu(self.conv38(x))\n",
    "        x = F.relu(self.conv39(x))\n",
    "        x = F.relu(self.conv40(x))\n",
    "        x = F.relu(self.conv41(x))\n",
    "        x = F.relu(self.conv42(x))\n",
    "        x = F.relu(self.conv43(x))\n",
    "        x = F.relu(self.conv44(x))\n",
    "        x = F.relu(self.conv45(x))\n",
    "        x = F.relu(self.conv46(x))\n",
    "        x = F.relu(self.conv47(x))\n",
    "        x = F.relu(self.conv48(x))\n",
    "        x = F.relu(self.conv49(x))\n",
    "        x = F.relu(self.conv50(x))\n",
    "        x = F.relu(self.conv51(x))\n",
    "        x = F.relu(self.conv52(x))\n",
    "        x = F.relu(self.conv53(x))\n",
    "\n",
    "\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mnist()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,  device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('{:2.0f}%  Loss {}'.format(100 * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('Loss: {}  Accuracy: {}%)\\n'.format(\n",
    "        test_loss, 100 * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 0 #\n",
      " 0%  Loss 2.297818422317505\n",
      " 8%  Loss 2.3035624027252197\n",
      "17%  Loss 2.2982606887817383\n",
      "25%  Loss 2.306532144546509\n",
      "33%  Loss 2.3108413219451904\n",
      "42%  Loss 2.3004724979400635\n",
      "50%  Loss 2.308532953262329\n",
      "58%  Loss 2.2933411598205566\n",
      "67%  Loss 2.3072328567504883\n",
      "75%  Loss 2.2946364879608154\n",
      "83%  Loss 2.2918643951416016\n",
      "92%  Loss 2.2930808067321777\n",
      "Loss: 2.301144715881348  Accuracy: 11.35%)\n",
      "\n",
      "# Epoch 1 #\n",
      " 0%  Loss 2.2986860275268555\n",
      " 8%  Loss 2.289917230606079\n",
      "17%  Loss 2.299856662750244\n",
      "25%  Loss 2.297154664993286\n",
      "33%  Loss 2.3028573989868164\n",
      "42%  Loss 2.3093507289886475\n",
      "50%  Loss 2.296455144882202\n",
      "58%  Loss 2.3064589500427246\n",
      "67%  Loss 2.303717613220215\n",
      "75%  Loss 2.3310399055480957\n",
      "83%  Loss 2.2961723804473877\n",
      "92%  Loss 2.290550470352173\n",
      "Loss: 2.3012802696228025  Accuracy: 11.35%)\n",
      "\n",
      "# Epoch 2 #\n",
      " 0%  Loss 2.2978012561798096\n",
      " 8%  Loss 2.301926612854004\n",
      "17%  Loss 2.3033406734466553\n",
      "25%  Loss 2.300546646118164\n",
      "33%  Loss 2.2976627349853516\n",
      "42%  Loss 2.3046207427978516\n",
      "50%  Loss 2.2925546169281006\n",
      "58%  Loss 2.309771776199341\n",
      "67%  Loss 2.292724370956421\n",
      "75%  Loss 2.294187068939209\n",
      "83%  Loss 2.2852158546447754\n",
      "92%  Loss 2.2968244552612305\n",
      "Loss: 2.301214448547363  Accuracy: 11.35%)\n",
      "\n",
      "# Epoch 3 #\n",
      " 0%  Loss 2.303870916366577\n",
      " 8%  Loss 2.3041069507598877\n",
      "17%  Loss 2.299253225326538\n",
      "25%  Loss 2.299377918243408\n",
      "33%  Loss 2.3043925762176514\n",
      "42%  Loss 2.30259370803833\n",
      "50%  Loss 2.288412570953369\n",
      "58%  Loss 2.306506633758545\n",
      "67%  Loss 2.3085098266601562\n",
      "75%  Loss 2.2858376502990723\n",
      "83%  Loss 2.297818422317505\n",
      "92%  Loss 2.3016197681427\n",
      "Loss: 2.301163301086426  Accuracy: 11.35%)\n",
      "\n",
      "# Epoch 4 #\n",
      " 0%  Loss 2.3153982162475586\n",
      " 8%  Loss 2.289963722229004\n",
      "17%  Loss 2.2944443225860596\n",
      "25%  Loss 2.3061819076538086\n",
      "33%  Loss 2.2949583530426025\n",
      "42%  Loss 2.296052932739258\n",
      "50%  Loss 2.307217836380005\n",
      "58%  Loss 2.302899122238159\n",
      "67%  Loss 2.3012094497680664\n",
      "75%  Loss 2.297572612762451\n",
      "83%  Loss 2.2931456565856934\n",
      "92%  Loss 2.306401491165161\n",
      "Loss: 2.301059502410889  Accuracy: 11.35%)\n",
      "\n",
      "# Epoch 5 #\n",
      " 0%  Loss 2.3105101585388184\n",
      " 8%  Loss 2.2944741249084473\n",
      "17%  Loss 2.2898428440093994\n",
      "25%  Loss 2.3013601303100586\n",
      "33%  Loss 2.305340051651001\n",
      "42%  Loss 2.2936553955078125\n",
      "50%  Loss 2.3000051975250244\n",
      "58%  Loss 2.3042428493499756\n",
      "67%  Loss 2.2961461544036865\n",
      "75%  Loss 2.305548667907715\n",
      "83%  Loss 2.2900028228759766\n",
      "92%  Loss 2.287191867828369\n",
      "Loss: 2.3011508529663085  Accuracy: 11.35%)\n",
      "\n",
      "# Epoch 6 #\n",
      " 0%  Loss 2.2894158363342285\n",
      " 8%  Loss 2.3058922290802\n",
      "17%  Loss 2.3109822273254395\n",
      "25%  Loss 2.29593563079834\n",
      "33%  Loss 2.3148815631866455\n",
      "42%  Loss 2.288696527481079\n",
      "50%  Loss 2.3064193725585938\n",
      "58%  Loss 2.310544967651367\n",
      "67%  Loss 2.319718360900879\n",
      "75%  Loss 2.2979445457458496\n",
      "83%  Loss 2.3081793785095215\n",
      "92%  Loss 2.294018030166626\n",
      "Loss: 2.3010523361206054  Accuracy: 11.35%)\n",
      "\n",
      "# Epoch 7 #\n",
      " 0%  Loss 2.300694704055786\n",
      " 8%  Loss 2.305385112762451\n",
      "17%  Loss 2.2917275428771973\n",
      "25%  Loss 2.2979700565338135\n",
      "33%  Loss 2.294194221496582\n",
      "42%  Loss 2.305403709411621\n",
      "50%  Loss 2.2872209548950195\n",
      "58%  Loss 2.3086493015289307\n",
      "67%  Loss 2.3164896965026855\n",
      "75%  Loss 2.2965667247772217\n",
      "83%  Loss 2.2987523078918457\n",
      "92%  Loss 2.3164989948272705\n",
      "Loss: 2.3012942390441893  Accuracy: 11.35%)\n",
      "\n",
      "# Epoch 8 #\n",
      " 0%  Loss 2.2999932765960693\n",
      " 8%  Loss 2.3035027980804443\n",
      "17%  Loss 2.300982713699341\n",
      "25%  Loss 2.3070015907287598\n",
      "33%  Loss 2.302417039871216\n",
      "42%  Loss 2.299065351486206\n",
      "50%  Loss 2.300493001937866\n",
      "58%  Loss 2.296687602996826\n",
      "67%  Loss 2.3027074337005615\n",
      "75%  Loss 2.3011577129364014\n",
      "83%  Loss 2.303825616836548\n",
      "92%  Loss 2.32025146484375\n",
      "Loss: 2.3011440170288084  Accuracy: 11.35%)\n",
      "\n",
      "# Epoch 9 #\n",
      " 0%  Loss 2.307267427444458\n",
      " 8%  Loss 2.306462526321411\n",
      "17%  Loss 2.2898921966552734\n",
      "25%  Loss 2.3064472675323486\n",
      "33%  Loss 2.3091607093811035\n",
      "42%  Loss 2.297109603881836\n",
      "50%  Loss 2.293829917907715\n",
      "58%  Loss 2.2944018840789795\n",
      "67%  Loss 2.2967569828033447\n",
      "75%  Loss 2.307102680206299\n",
      "83%  Loss 2.3065290451049805\n",
      "92%  Loss 2.304205894470215\n",
      "Loss: 2.30097391204834  Accuracy: 11.35%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "# training only 30 epoches\n",
    "for epoch in range(10):\n",
    "    print('# Epoch {} #'.format(epoch))\n",
    "    train(model,  device, train_loader, optimizer)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Save and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The main function of this page is to convert pytorch model to onnx model.\n",
    "Convertion from pytorch model to onnx model is primary so that a critical\n",
    "problem is caused that Layer name of pytorch model fail to convert to onnx\n",
    "layer name directly. To solve it, we wrap pytorch model in new wrapper which\n",
    "multiply bits number and input before computation of each op. Only in this\n",
    "way can onnx model get bits number of corresponded layer.\n",
    "\"\"\"\n",
    "\n",
    "class LayernameModuleWrapper(torch.nn.Module):\n",
    "    def __init__(self, module, module_bits) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        module : torch.nn.Module\n",
    "            Layer module of pytorch model\n",
    "        module_bits : int\n",
    "            Bits width setting for module\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        self.module_bits = module_bits\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs*self.module_bits\n",
    "        inputs = self.module(inputs)\n",
    "        return inputs\n",
    "\n",
    "def _setattr(model, name, module):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : pytorch model\n",
    "        The model to speedup by quantization\n",
    "    name : str\n",
    "        name of pytorch module\n",
    "    module : torch.nn.Module\n",
    "        Layer module of pytorch model\n",
    "    \"\"\"\n",
    "    name_list = name.split(\".\")\n",
    "    for name in name_list[:-1]:\n",
    "        model = getattr(model, name)\n",
    "    setattr(model, name_list[-1], module)\n",
    "\n",
    "def unwrapper(model_onnx, index2name, config):\n",
    "    \"\"\"\n",
    "    Fill onnx config and remove wrapper node in onnx\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_onnx : onnx model\n",
    "        Onnx model which is converted from pytorch model\n",
    "    index2name : dict\n",
    "        Dictionary of layer index and name\n",
    "    config : dict\n",
    "        Config recording name of layers and calibration parameters\n",
    "    Returns\n",
    "    -------\n",
    "    onnx model\n",
    "        Onnx model which is converted from pytorch model\n",
    "    dict\n",
    "        The configuration of onnx model layers and calibration parameters\n",
    "    \"\"\"\n",
    "    # Support Gemm, Conv, Relu, Clip(Relu6) and Maxpool\n",
    "    support_op = ['Gemm', 'Conv', 'Relu', 'Clip', 'MaxP']\n",
    "    idx = 0\n",
    "    onnx_config = {}\n",
    "    while idx < len(model_onnx.graph.node):\n",
    "        nd = model_onnx.graph.node[idx]\n",
    "        if nd.name[0:4] in support_op and  idx > 1:\n",
    "            # Grad constant node and multiply node\n",
    "            const_nd = model_onnx.graph.node[idx-2]\n",
    "            mul_nd = model_onnx.graph.node[idx-1]\n",
    "            # Get index number which is transferred by constant node\n",
    "            index = int(onnx.numpy_helper.to_array(const_nd.attribute[0].t))\n",
    "            if index != -1:\n",
    "                name = index2name[index]\n",
    "                onnx_config[nd.name] = config[name]\n",
    "            nd.input[0] = mul_nd.input[0]\n",
    "            # Remove constant node and multiply node\n",
    "            model_onnx.graph.node.remove(const_nd)\n",
    "            model_onnx.graph.node.remove(mul_nd)\n",
    "            idx = idx-2\n",
    "        idx = idx+1\n",
    "    return model_onnx, onnx_config\n",
    "\n",
    "def torch_to_onnx(model, input_shape, model_path, input_names, output_names):\n",
    "    \"\"\"\n",
    "    Convert torch model to onnx model and get layer bits config of onnx model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : pytorch model\n",
    "        The model to speedup by quantization\n",
    "    config : dict\n",
    "        Config recording bits number and name of layers\n",
    "    input_shape : tuple\n",
    "        The input shape of model, shall pass it to torch.onnx.export\n",
    "    model_path : str\n",
    "        The path user want to store onnx model which is converted from pytorch model\n",
    "    input_names : list\n",
    "        Input name of onnx model providing for torch.onnx.export to generate onnx model\n",
    "    output_name : list\n",
    "        Output name of onnx model providing for torch.onnx.export to generate onnx model\n",
    "    Returns\n",
    "    -------\n",
    "    onnx model\n",
    "        Onnx model which is converted from pytorch model\n",
    "    dict\n",
    "        The configuration of onnx model layers and calibration parameters\n",
    "    \"\"\"\n",
    "    # Convert torch model to onnx model and save it in model_path\n",
    "    dummy_input = torch.randn(input_shape)\n",
    "    model.to('cpu')\n",
    "    torch.onnx.export(model, dummy_input, model_path, verbose=False, input_names=input_names, output_names=output_names, export_params=True)\n",
    "\n",
    "    # Load onnx model\n",
    "    model_onnx = onnx.load(model_path)\n",
    "    model_onnx, onnx_config = unwrapper(model_onnx, index2name, config)\n",
    "    onnx.save(model_onnx, model_path)\n",
    "\n",
    "    onnx.checker.check_model(model_onnx)\n",
    "    return model_onnx, onnx_config\n",
    "\n",
    "\n",
    "\n",
    "def export_model_to_onnx(model, input_shape=(1,3,28,28), path=\"mnistrB.onnx\"):\n",
    "\n",
    "    dummy_input = torch.randn(input_shape)\n",
    "    model.to('cpu')\n",
    "        \n",
    "    # very important or must leave out - not sure need to test again...\n",
    "    #traced = torch.jit.trace(model, input_dimension)\n",
    "    print(\"------------- Exporting to onnx\")\n",
    "    torch.onnx.export(\n",
    "                      model, \n",
    "                      dummy_input, \n",
    "                      path,\n",
    "                      opset_version=7,\n",
    "                      verbose=True,\n",
    "                      export_params=True, \n",
    "                      input_names=['input'],\n",
    "                      output_names=['output'],\n",
    "                      dynamic_axes=None\n",
    "    )\n",
    "    \n",
    "    print(\"------------- Checking exported model\")\n",
    "    \n",
    "    # Load the ONNX model\n",
    "    onnx_model = onnx.load(path)\n",
    "\n",
    "    # Check that the IR is well formed\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "\n",
    "    # Print a Human readable representation of the graph\n",
    "    print( onnx.helper.printable_graph(onnx_model.graph) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Exporting to onnx\n",
      "graph(%input : Float(1, 3, 28, 28, strides=[2352, 784, 28, 1], requires_grad=0, device=cpu),\n",
      "      %conv1.weight : Float(20, 3, 5, 5, strides=[75, 25, 5, 1], requires_grad=1, device=cpu),\n",
      "      %conv1.bias : Float(20, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv2.weight : Float(20, 20, 5, 5, strides=[500, 25, 5, 1], requires_grad=1, device=cpu),\n",
      "      %conv2.bias : Float(20, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv3.weight : Float(50, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv3.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv4.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv4.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv5.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv5.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv6.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv6.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv7.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv7.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv8.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv8.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv9.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv9.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv10.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv10.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv11.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv11.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv12.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv12.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv13.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv13.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv14.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv14.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv15.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv15.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv16.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv16.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv17.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv17.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv18.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv18.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv19.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv19.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv20.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv20.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv21.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv21.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv22.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv22.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv23.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv23.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv24.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv24.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv25.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv25.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv26.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv26.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv27.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv27.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv28.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv28.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv29.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv29.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv30.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv30.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv31.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv31.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv32.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv32.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv33.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv33.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv34.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv34.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv35.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv35.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv36.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv36.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv37.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv37.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv38.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv38.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv39.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv39.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv40.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv40.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv41.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv41.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv42.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv42.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv43.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv43.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv44.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv44.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv45.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv45.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv46.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv46.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv47.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv47.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv48.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv48.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv49.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv49.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv50.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv50.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv51.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv51.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv52.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv52.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %conv53.weight : Float(50, 50, 1, 1, strides=[50, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv53.bias : Float(50, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fc1.weight : Float(500, 800, strides=[800, 1], requires_grad=1, device=cpu),\n",
      "      %fc1.bias : Float(500, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fc2.weight : Float(10, 500, strides=[500, 1], requires_grad=1, device=cpu),\n",
      "      %fc2.bias : Float(10, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %111 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%input, %conv1.weight, %conv1.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %112 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=1, device=cpu) = onnx::Relu(%111) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %113 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%112) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:719:0\n",
      "  %114 : Float(1, 20, 8, 8, strides=[1280, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%113, %conv2.weight, %conv2.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %115 : Float(1, 20, 8, 8, strides=[1280, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%114) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %116 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%115, %conv3.weight, %conv3.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %117 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%116) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %118 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%117, %conv4.weight, %conv4.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %119 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%118) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %120 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%119, %conv5.weight, %conv5.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %121 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%120) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %122 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%121, %conv6.weight, %conv6.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %123 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%122) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %124 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%123, %conv7.weight, %conv7.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %125 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%124) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %126 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%125, %conv8.weight, %conv8.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %127 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%126) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %128 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%127, %conv9.weight, %conv9.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %129 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%128) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %130 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%129, %conv10.weight, %conv10.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %131 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%130) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %132 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%131, %conv11.weight, %conv11.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %133 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%132) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %134 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%133, %conv12.weight, %conv12.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %135 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%134) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %136 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%135, %conv13.weight, %conv13.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %137 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%136) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %138 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%137, %conv14.weight, %conv14.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %139 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%138) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %140 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%139, %conv15.weight, %conv15.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %141 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%140) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %142 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%141, %conv16.weight, %conv16.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %143 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%142) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %144 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%143, %conv17.weight, %conv17.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %145 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%144) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %146 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%145, %conv18.weight, %conv18.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %147 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%146) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %148 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%147, %conv19.weight, %conv19.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %149 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%148) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %150 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%149, %conv20.weight, %conv20.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %151 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%150) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %152 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%151, %conv21.weight, %conv21.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %153 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%152) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %154 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%153, %conv22.weight, %conv22.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %155 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%154) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %156 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%155, %conv23.weight, %conv23.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %157 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%156) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %158 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%157, %conv24.weight, %conv24.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %159 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%158) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %160 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%159, %conv25.weight, %conv25.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %161 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%160) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %162 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%161, %conv26.weight, %conv26.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %163 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%162) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %164 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%163, %conv27.weight, %conv27.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %165 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%164) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %166 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%165, %conv28.weight, %conv28.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %167 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%166) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %168 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%167, %conv29.weight, %conv29.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %169 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%168) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %170 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%169, %conv30.weight, %conv30.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %171 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%170) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %172 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%171, %conv31.weight, %conv31.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %173 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%172) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %174 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%173, %conv32.weight, %conv32.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %175 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%174) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %176 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%175, %conv33.weight, %conv33.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %177 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%176) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %178 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%177, %conv34.weight, %conv34.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %179 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%178) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %180 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%179, %conv35.weight, %conv35.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %181 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%180) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %182 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%181, %conv36.weight, %conv36.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %183 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%182) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %184 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%183, %conv37.weight, %conv37.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %185 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%184) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %186 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%185, %conv38.weight, %conv38.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %187 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%186) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %188 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%187, %conv39.weight, %conv39.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %189 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%188) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %190 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%189, %conv40.weight, %conv40.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %191 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%190) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %192 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%191, %conv41.weight, %conv41.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %193 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%192) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %194 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%193, %conv42.weight, %conv42.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %195 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%194) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %196 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%195, %conv43.weight, %conv43.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %197 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%196) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %198 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%197, %conv44.weight, %conv44.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %199 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%198) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %200 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%199, %conv45.weight, %conv45.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %201 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%200) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %202 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%201, %conv46.weight, %conv46.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %203 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%202) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %204 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%203, %conv47.weight, %conv47.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %205 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%204) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %206 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%205, %conv48.weight, %conv48.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %207 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%206) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %208 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%207, %conv49.weight, %conv49.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %209 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%208) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %210 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%209, %conv50.weight, %conv50.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %211 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%210) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %212 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%211, %conv51.weight, %conv51.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %213 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%212) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %214 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%213, %conv52.weight, %conv52.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %215 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%214) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %216 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%215, %conv53.weight, %conv53.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:442:0\n",
      "  %217 : Float(1, 50, 8, 8, strides=[3200, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu(%216) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %218 : Float(1, 50, 4, 4, strides=[800, 16, 4, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%217) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:719:0\n",
      "  %219 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=  -1  800 [ CPUDoubleType{2} ]]()\n",
      "  %225 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Cast[to=7](%219)\n",
      "  %220 : Float(1, 800, strides=[800, 1], requires_grad=1, device=cpu) = onnx::Reshape(%218, %225) # /tmp/ipykernel_20545/1122413658.py:132:0\n",
      "  %221 : Float(1, 500, strides=[500, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%220, %fc1.weight, %fc1.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1848:0\n",
      "  %222 : Float(1, 500, strides=[500, 1], requires_grad=1, device=cpu) = onnx::Relu(%221) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1299:0\n",
      "  %223 : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%222, %fc2.weight, %fc2.bias) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1848:0\n",
      "  %output : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::LogSoftmax[axis=1](%223) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1769:0\n",
      "  return (%output)\n",
      "\n",
      "------------- Checking exported model\n",
      "graph torch-jit-export (\n",
      "  %input[FLOAT, 1x3x28x28]\n",
      ") optional inputs with matching initializers (\n",
      "  %conv1.weight[FLOAT, 20x3x5x5]\n",
      "  %conv1.bias[FLOAT, 20]\n",
      "  %conv2.weight[FLOAT, 20x20x5x5]\n",
      "  %conv2.bias[FLOAT, 20]\n",
      "  %conv3.weight[FLOAT, 50x20x1x1]\n",
      "  %conv3.bias[FLOAT, 50]\n",
      "  %conv4.weight[FLOAT, 50x50x1x1]\n",
      "  %conv4.bias[FLOAT, 50]\n",
      "  %conv5.weight[FLOAT, 50x50x1x1]\n",
      "  %conv5.bias[FLOAT, 50]\n",
      "  %conv6.weight[FLOAT, 50x50x1x1]\n",
      "  %conv6.bias[FLOAT, 50]\n",
      "  %conv7.weight[FLOAT, 50x50x1x1]\n",
      "  %conv7.bias[FLOAT, 50]\n",
      "  %conv8.weight[FLOAT, 50x50x1x1]\n",
      "  %conv8.bias[FLOAT, 50]\n",
      "  %conv9.weight[FLOAT, 50x50x1x1]\n",
      "  %conv9.bias[FLOAT, 50]\n",
      "  %conv10.weight[FLOAT, 50x50x1x1]\n",
      "  %conv10.bias[FLOAT, 50]\n",
      "  %conv11.weight[FLOAT, 50x50x1x1]\n",
      "  %conv11.bias[FLOAT, 50]\n",
      "  %conv12.weight[FLOAT, 50x50x1x1]\n",
      "  %conv12.bias[FLOAT, 50]\n",
      "  %conv13.weight[FLOAT, 50x50x1x1]\n",
      "  %conv13.bias[FLOAT, 50]\n",
      "  %conv14.weight[FLOAT, 50x50x1x1]\n",
      "  %conv14.bias[FLOAT, 50]\n",
      "  %conv15.weight[FLOAT, 50x50x1x1]\n",
      "  %conv15.bias[FLOAT, 50]\n",
      "  %conv16.weight[FLOAT, 50x50x1x1]\n",
      "  %conv16.bias[FLOAT, 50]\n",
      "  %conv17.weight[FLOAT, 50x50x1x1]\n",
      "  %conv17.bias[FLOAT, 50]\n",
      "  %conv18.weight[FLOAT, 50x50x1x1]\n",
      "  %conv18.bias[FLOAT, 50]\n",
      "  %conv19.weight[FLOAT, 50x50x1x1]\n",
      "  %conv19.bias[FLOAT, 50]\n",
      "  %conv20.weight[FLOAT, 50x50x1x1]\n",
      "  %conv20.bias[FLOAT, 50]\n",
      "  %conv21.weight[FLOAT, 50x50x1x1]\n",
      "  %conv21.bias[FLOAT, 50]\n",
      "  %conv22.weight[FLOAT, 50x50x1x1]\n",
      "  %conv22.bias[FLOAT, 50]\n",
      "  %conv23.weight[FLOAT, 50x50x1x1]\n",
      "  %conv23.bias[FLOAT, 50]\n",
      "  %conv24.weight[FLOAT, 50x50x1x1]\n",
      "  %conv24.bias[FLOAT, 50]\n",
      "  %conv25.weight[FLOAT, 50x50x1x1]\n",
      "  %conv25.bias[FLOAT, 50]\n",
      "  %conv26.weight[FLOAT, 50x50x1x1]\n",
      "  %conv26.bias[FLOAT, 50]\n",
      "  %conv27.weight[FLOAT, 50x50x1x1]\n",
      "  %conv27.bias[FLOAT, 50]\n",
      "  %conv28.weight[FLOAT, 50x50x1x1]\n",
      "  %conv28.bias[FLOAT, 50]\n",
      "  %conv29.weight[FLOAT, 50x50x1x1]\n",
      "  %conv29.bias[FLOAT, 50]\n",
      "  %conv30.weight[FLOAT, 50x50x1x1]\n",
      "  %conv30.bias[FLOAT, 50]\n",
      "  %conv31.weight[FLOAT, 50x50x1x1]\n",
      "  %conv31.bias[FLOAT, 50]\n",
      "  %conv32.weight[FLOAT, 50x50x1x1]\n",
      "  %conv32.bias[FLOAT, 50]\n",
      "  %conv33.weight[FLOAT, 50x50x1x1]\n",
      "  %conv33.bias[FLOAT, 50]\n",
      "  %conv34.weight[FLOAT, 50x50x1x1]\n",
      "  %conv34.bias[FLOAT, 50]\n",
      "  %conv35.weight[FLOAT, 50x50x1x1]\n",
      "  %conv35.bias[FLOAT, 50]\n",
      "  %conv36.weight[FLOAT, 50x50x1x1]\n",
      "  %conv36.bias[FLOAT, 50]\n",
      "  %conv37.weight[FLOAT, 50x50x1x1]\n",
      "  %conv37.bias[FLOAT, 50]\n",
      "  %conv38.weight[FLOAT, 50x50x1x1]\n",
      "  %conv38.bias[FLOAT, 50]\n",
      "  %conv39.weight[FLOAT, 50x50x1x1]\n",
      "  %conv39.bias[FLOAT, 50]\n",
      "  %conv40.weight[FLOAT, 50x50x1x1]\n",
      "  %conv40.bias[FLOAT, 50]\n",
      "  %conv41.weight[FLOAT, 50x50x1x1]\n",
      "  %conv41.bias[FLOAT, 50]\n",
      "  %conv42.weight[FLOAT, 50x50x1x1]\n",
      "  %conv42.bias[FLOAT, 50]\n",
      "  %conv43.weight[FLOAT, 50x50x1x1]\n",
      "  %conv43.bias[FLOAT, 50]\n",
      "  %conv44.weight[FLOAT, 50x50x1x1]\n",
      "  %conv44.bias[FLOAT, 50]\n",
      "  %conv45.weight[FLOAT, 50x50x1x1]\n",
      "  %conv45.bias[FLOAT, 50]\n",
      "  %conv46.weight[FLOAT, 50x50x1x1]\n",
      "  %conv46.bias[FLOAT, 50]\n",
      "  %conv47.weight[FLOAT, 50x50x1x1]\n",
      "  %conv47.bias[FLOAT, 50]\n",
      "  %conv48.weight[FLOAT, 50x50x1x1]\n",
      "  %conv48.bias[FLOAT, 50]\n",
      "  %conv49.weight[FLOAT, 50x50x1x1]\n",
      "  %conv49.bias[FLOAT, 50]\n",
      "  %conv50.weight[FLOAT, 50x50x1x1]\n",
      "  %conv50.bias[FLOAT, 50]\n",
      "  %conv51.weight[FLOAT, 50x50x1x1]\n",
      "  %conv51.bias[FLOAT, 50]\n",
      "  %conv52.weight[FLOAT, 50x50x1x1]\n",
      "  %conv52.bias[FLOAT, 50]\n",
      "  %conv53.weight[FLOAT, 50x50x1x1]\n",
      "  %conv53.bias[FLOAT, 50]\n",
      "  %fc1.weight[FLOAT, 500x800]\n",
      "  %fc1.bias[FLOAT, 500]\n",
      "  %fc2.weight[FLOAT, 10x500]\n",
      "  %fc2.bias[FLOAT, 10]\n",
      ") {\n",
      "  %111 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [0, 0, 0, 0], strides = [1, 1]](%input, %conv1.weight, %conv1.bias)\n",
      "  %112 = Relu(%111)\n",
      "  %113 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%112)\n",
      "  %114 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [0, 0, 0, 0], strides = [1, 1]](%113, %conv2.weight, %conv2.bias)\n",
      "  %115 = Relu(%114)\n",
      "  %116 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%115, %conv3.weight, %conv3.bias)\n",
      "  %117 = Relu(%116)\n",
      "  %118 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%117, %conv4.weight, %conv4.bias)\n",
      "  %119 = Relu(%118)\n",
      "  %120 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%119, %conv5.weight, %conv5.bias)\n",
      "  %121 = Relu(%120)\n",
      "  %122 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%121, %conv6.weight, %conv6.bias)\n",
      "  %123 = Relu(%122)\n",
      "  %124 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%123, %conv7.weight, %conv7.bias)\n",
      "  %125 = Relu(%124)\n",
      "  %126 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%125, %conv8.weight, %conv8.bias)\n",
      "  %127 = Relu(%126)\n",
      "  %128 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%127, %conv9.weight, %conv9.bias)\n",
      "  %129 = Relu(%128)\n",
      "  %130 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%129, %conv10.weight, %conv10.bias)\n",
      "  %131 = Relu(%130)\n",
      "  %132 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%131, %conv11.weight, %conv11.bias)\n",
      "  %133 = Relu(%132)\n",
      "  %134 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%133, %conv12.weight, %conv12.bias)\n",
      "  %135 = Relu(%134)\n",
      "  %136 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%135, %conv13.weight, %conv13.bias)\n",
      "  %137 = Relu(%136)\n",
      "  %138 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%137, %conv14.weight, %conv14.bias)\n",
      "  %139 = Relu(%138)\n",
      "  %140 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%139, %conv15.weight, %conv15.bias)\n",
      "  %141 = Relu(%140)\n",
      "  %142 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%141, %conv16.weight, %conv16.bias)\n",
      "  %143 = Relu(%142)\n",
      "  %144 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%143, %conv17.weight, %conv17.bias)\n",
      "  %145 = Relu(%144)\n",
      "  %146 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%145, %conv18.weight, %conv18.bias)\n",
      "  %147 = Relu(%146)\n",
      "  %148 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%147, %conv19.weight, %conv19.bias)\n",
      "  %149 = Relu(%148)\n",
      "  %150 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%149, %conv20.weight, %conv20.bias)\n",
      "  %151 = Relu(%150)\n",
      "  %152 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%151, %conv21.weight, %conv21.bias)\n",
      "  %153 = Relu(%152)\n",
      "  %154 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%153, %conv22.weight, %conv22.bias)\n",
      "  %155 = Relu(%154)\n",
      "  %156 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%155, %conv23.weight, %conv23.bias)\n",
      "  %157 = Relu(%156)\n",
      "  %158 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%157, %conv24.weight, %conv24.bias)\n",
      "  %159 = Relu(%158)\n",
      "  %160 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%159, %conv25.weight, %conv25.bias)\n",
      "  %161 = Relu(%160)\n",
      "  %162 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%161, %conv26.weight, %conv26.bias)\n",
      "  %163 = Relu(%162)\n",
      "  %164 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%163, %conv27.weight, %conv27.bias)\n",
      "  %165 = Relu(%164)\n",
      "  %166 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%165, %conv28.weight, %conv28.bias)\n",
      "  %167 = Relu(%166)\n",
      "  %168 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%167, %conv29.weight, %conv29.bias)\n",
      "  %169 = Relu(%168)\n",
      "  %170 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%169, %conv30.weight, %conv30.bias)\n",
      "  %171 = Relu(%170)\n",
      "  %172 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%171, %conv31.weight, %conv31.bias)\n",
      "  %173 = Relu(%172)\n",
      "  %174 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%173, %conv32.weight, %conv32.bias)\n",
      "  %175 = Relu(%174)\n",
      "  %176 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%175, %conv33.weight, %conv33.bias)\n",
      "  %177 = Relu(%176)\n",
      "  %178 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%177, %conv34.weight, %conv34.bias)\n",
      "  %179 = Relu(%178)\n",
      "  %180 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%179, %conv35.weight, %conv35.bias)\n",
      "  %181 = Relu(%180)\n",
      "  %182 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%181, %conv36.weight, %conv36.bias)\n",
      "  %183 = Relu(%182)\n",
      "  %184 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%183, %conv37.weight, %conv37.bias)\n",
      "  %185 = Relu(%184)\n",
      "  %186 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%185, %conv38.weight, %conv38.bias)\n",
      "  %187 = Relu(%186)\n",
      "  %188 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%187, %conv39.weight, %conv39.bias)\n",
      "  %189 = Relu(%188)\n",
      "  %190 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%189, %conv40.weight, %conv40.bias)\n",
      "  %191 = Relu(%190)\n",
      "  %192 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%191, %conv41.weight, %conv41.bias)\n",
      "  %193 = Relu(%192)\n",
      "  %194 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%193, %conv42.weight, %conv42.bias)\n",
      "  %195 = Relu(%194)\n",
      "  %196 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%195, %conv43.weight, %conv43.bias)\n",
      "  %197 = Relu(%196)\n",
      "  %198 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%197, %conv44.weight, %conv44.bias)\n",
      "  %199 = Relu(%198)\n",
      "  %200 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%199, %conv45.weight, %conv45.bias)\n",
      "  %201 = Relu(%200)\n",
      "  %202 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%201, %conv46.weight, %conv46.bias)\n",
      "  %203 = Relu(%202)\n",
      "  %204 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%203, %conv47.weight, %conv47.bias)\n",
      "  %205 = Relu(%204)\n",
      "  %206 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%205, %conv48.weight, %conv48.bias)\n",
      "  %207 = Relu(%206)\n",
      "  %208 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%207, %conv49.weight, %conv49.bias)\n",
      "  %209 = Relu(%208)\n",
      "  %210 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%209, %conv50.weight, %conv50.bias)\n",
      "  %211 = Relu(%210)\n",
      "  %212 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%211, %conv51.weight, %conv51.bias)\n",
      "  %213 = Relu(%212)\n",
      "  %214 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%213, %conv52.weight, %conv52.bias)\n",
      "  %215 = Relu(%214)\n",
      "  %216 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%215, %conv53.weight, %conv53.bias)\n",
      "  %217 = Relu(%216)\n",
      "  %218 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%217)\n",
      "  %219 = Constant[value = <Tensor>]()\n",
      "  %225 = Cast[to = 7](%219)\n",
      "  %220 = Reshape(%218, %225)\n",
      "  %221 = Gemm[alpha = 1, beta = 1, transB = 1](%220, %fc1.weight, %fc1.bias)\n",
      "  %222 = Relu(%221)\n",
      "  %223 = Gemm[alpha = 1, beta = 1, transB = 1](%222, %fc2.weight, %fc2.bias)\n",
      "  %output = LogSoftmax[axis = 1](%223)\n",
      "  return %output\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "export_model_to_onnx(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beebd582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(mnist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
