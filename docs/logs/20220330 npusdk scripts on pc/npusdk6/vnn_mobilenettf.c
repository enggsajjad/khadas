/****************************************************************************
*   Generated by ACUITY 5.21.1_0702
*   Match ovxlib 1.1.30
*
*   Neural Network appliction network definition source file
****************************************************************************/
/*-------------------------------------------
                   Includes
 -------------------------------------------*/
#include <stdio.h>
#include <stdlib.h>

#include "vsi_nn_pub.h"

#include "vnn_global.h"
#include "vnn_mobilenettf.h"

/*-------------------------------------------
                   Macros
 -------------------------------------------*/

#define NEW_VXNODE(_node, _type, _in, _out, _uid) do {\
        _node = vsi_nn_AddNode( graph, _type, _in, _out, NULL );\
        if( NULL == _node ) {\
            goto error;\
        }\
        _node->uid = (uint32_t)_uid;\
    } while(0)

#define NEW_VIRTUAL_TENSOR(_id, _attr, _dtype) do {\
        memset( _attr.size, 0, VSI_NN_MAX_DIM_NUM * sizeof(uint32_t));\
        _attr.dim_num = VSI_NN_DIM_AUTO;\
        _attr.vtl = !VNN_APP_DEBUG;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set const tensor dims out of this macro.
#define NEW_CONST_TENSOR(_id, _attr, _dtype, _ofst, _size) do {\
        data = load_data( fp, _ofst, _size  );\
        _attr.vtl = FALSE;\
        _attr.is_const = TRUE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, data );\
        free( data );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR_FROM_HANDLE(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensorFromHandle( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

#define NET_NODE_NUM            (33)
#define NET_NORM_TENSOR_NUM     (2)
#define NET_CONST_TENSOR_NUM    (56)
#define NET_VIRTUAL_TENSOR_NUM  (33)
#define NET_TOTAL_TENSOR_NUM    (NET_NORM_TENSOR_NUM + NET_CONST_TENSOR_NUM + NET_VIRTUAL_TENSOR_NUM)

/*-------------------------------------------
               Local Variables
 -------------------------------------------*/

/*-------------------------------------------
                  Functions
 -------------------------------------------*/
static uint8_t* load_data
    (
    FILE  * fp,
    size_t  ofst,
    size_t  sz
    )
{
    uint8_t* data;
    int32_t ret;
    data = NULL;
    if( NULL == fp )
    {
        return NULL;
    }

    ret = fseek(fp, ofst, SEEK_SET);
    if (ret != 0)
    {
        VSILOGE("blob seek failure.");
        return NULL;
    }

    data = (uint8_t*)malloc(sz);
    if (data == NULL)
    {
        VSILOGE("buffer malloc failure.");
        return NULL;
    }
    ret = fread(data, 1, sz, fp);
    return data;
} /* load_data() */

vsi_nn_graph_t * vnn_CreateMobilenetTf
    (
    const char * data_file_name,
    vsi_nn_context_t in_ctx,
    const vsi_nn_preprocess_map_element_t * pre_process_map,
    uint32_t pre_process_map_count,
    const vsi_nn_postprocess_map_element_t * post_process_map,
    uint32_t post_process_map_count
    )
{
    uint32_t                _infinity = VSI_NN_FLOAT32_INF;
    vsi_status              status;
    vsi_bool                release_ctx;
    vsi_nn_context_t        ctx;
    vsi_nn_graph_t *        graph;
    vsi_nn_node_t *         node[NET_NODE_NUM];
    vsi_nn_tensor_id_t      norm_tensor[NET_NORM_TENSOR_NUM];
    vsi_nn_tensor_id_t      const_tensor[NET_CONST_TENSOR_NUM];
    vsi_nn_tensor_attr_t    attr;
    FILE *                  fp;
    uint8_t *               data;
    uint32_t                i = 0;
    char *                  use_img_process_s;
    int32_t                 enable_pre_post_process = 0;
    vsi_bool                sort = FALSE;

    uint32_t   perm_1[] = { 1, 2, 0, 3 };
    uint32_t   perm_2[] = { 2, 0, 1, 3 };
    uint32_t   shape_1[] = { 1001, 1 };




    (void)(_infinity);
    ctx = NULL;
    graph = NULL;
    status = VSI_FAILURE;
    memset( &attr, 0, sizeof( attr ) );

    fp = fopen( data_file_name, "rb" );
    if( NULL == fp )
    {
        VSILOGE( "Open file %s failed.", data_file_name );
        goto error;
    }

    if( NULL == in_ctx )
    {
        ctx = vsi_nn_CreateContext();
    }
    else
    {
        ctx = in_ctx;
    }

    use_img_process_s = getenv( "VSI_USE_IMAGE_PROCESS" );
    if( use_img_process_s )
    {
        enable_pre_post_process = atoi(use_img_process_s);
    }

    graph = vsi_nn_CreateGraph( ctx, NET_TOTAL_TENSOR_NUM, NET_NODE_NUM );
    if( NULL == graph )
    {
        VSILOGE( "Create graph fail." );
        goto error;
    }
    vsi_nn_SetGraphVersion( graph, VNN_VERSION_MAJOR, VNN_VERSION_MINOR, VNN_VERSION_PATCH );
    vsi_nn_SetGraphInputs( graph, NULL, 1 );
    vsi_nn_SetGraphOutputs( graph, NULL, 1 );

/*-----------------------------------------
  Register client ops
 -----------------------------------------*/


/*-----------------------------------------
  Node definitions
 -----------------------------------------*/

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_87_acuity_mark_perm_8
      var       - node[0]
      name      - MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_87_acuity_mark_perm
      operation - permute
      input     - [3, 224, 224, 1]
      output    - [224, 224, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[0], VSI_NN_OP_PERMUTE, 1, 1, 8);
    node[0]->nn_param.permute.perm = perm_1;
    node[0]->nn_param.permute.dim_num = 4;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_87
      var       - node[1]
      name      - MobilenetV1/MobilenetV1/Conv2d_0/Conv2D
      operation - convolution
      input     - [224, 224, 3, 1]
      filter    - [3, 3, 3, 32]
      output    - [112, 112, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[1], VSI_NN_OP_CONV2D, 3, 1, 87);
    node[1]->nn_param.conv2d.ksize[0] = 3;
    node[1]->nn_param.conv2d.ksize[1] = 3;
    node[1]->nn_param.conv2d.weights = 32;
    node[1]->nn_param.conv2d.stride[0] = 2;
    node[1]->nn_param.conv2d.stride[1] = 2;
    node[1]->nn_param.conv2d.pad[0] = 0;
    node[1]->nn_param.conv2d.pad[1] = 1;
    node[1]->nn_param.conv2d.pad[2] = 0;
    node[1]->nn_param.conv2d.pad[3] = 1;
    node[1]->nn_param.conv2d.group = 1;
    node[1]->nn_param.conv2d.dilation[0] = 1;
    node[1]->nn_param.conv2d.dilation[1] = 1;
    node[1]->nn_param.conv2d.multiplier = 0;
    node[1]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[1]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[1]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise_84
      var       - node[2]
      name      - MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise
      operation - convolution
      input     - [112, 112, 32, 1]
      filter    - [3, 3, 32, 1]
      output    - [112, 112, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[2], VSI_NN_OP_CONV2D, 3, 1, 84);
    node[2]->nn_param.conv2d.ksize[0] = 3;
    node[2]->nn_param.conv2d.ksize[1] = 3;
    node[2]->nn_param.conv2d.weights = 32;
    node[2]->nn_param.conv2d.stride[0] = 1;
    node[2]->nn_param.conv2d.stride[1] = 1;
    node[2]->nn_param.conv2d.pad[0] = 1;
    node[2]->nn_param.conv2d.pad[1] = 1;
    node[2]->nn_param.conv2d.pad[2] = 1;
    node[2]->nn_param.conv2d.pad[3] = 1;
    node[2]->nn_param.conv2d.group = 32;
    node[2]->nn_param.conv2d.dilation[0] = 1;
    node[2]->nn_param.conv2d.dilation[1] = 1;
    node[2]->nn_param.conv2d.multiplier = 1;
    node[2]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[2]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[2]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_81
      var       - node[3]
      name      - MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D
      operation - convolution
      input     - [112, 112, 32, 1]
      filter    - [1, 1, 32, 64]
      output    - [112, 112, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[3], VSI_NN_OP_CONV2D, 3, 1, 81);
    node[3]->nn_param.conv2d.ksize[0] = 1;
    node[3]->nn_param.conv2d.ksize[1] = 1;
    node[3]->nn_param.conv2d.weights = 64;
    node[3]->nn_param.conv2d.stride[0] = 1;
    node[3]->nn_param.conv2d.stride[1] = 1;
    node[3]->nn_param.conv2d.pad[0] = 0;
    node[3]->nn_param.conv2d.pad[1] = 0;
    node[3]->nn_param.conv2d.pad[2] = 0;
    node[3]->nn_param.conv2d.pad[3] = 0;
    node[3]->nn_param.conv2d.group = 1;
    node[3]->nn_param.conv2d.dilation[0] = 1;
    node[3]->nn_param.conv2d.dilation[1] = 1;
    node[3]->nn_param.conv2d.multiplier = 0;
    node[3]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[3]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[3]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_2_depthwise/depthwise_78
      var       - node[4]
      name      - MobilenetV1/MobilenetV1/Conv2d_2_depthwise/depthwise
      operation - convolution
      input     - [112, 112, 64, 1]
      filter    - [3, 3, 64, 1]
      output    - [56, 56, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[4], VSI_NN_OP_CONV2D, 3, 1, 78);
    node[4]->nn_param.conv2d.ksize[0] = 3;
    node[4]->nn_param.conv2d.ksize[1] = 3;
    node[4]->nn_param.conv2d.weights = 64;
    node[4]->nn_param.conv2d.stride[0] = 2;
    node[4]->nn_param.conv2d.stride[1] = 2;
    node[4]->nn_param.conv2d.pad[0] = 0;
    node[4]->nn_param.conv2d.pad[1] = 1;
    node[4]->nn_param.conv2d.pad[2] = 0;
    node[4]->nn_param.conv2d.pad[3] = 1;
    node[4]->nn_param.conv2d.group = 64;
    node[4]->nn_param.conv2d.dilation[0] = 1;
    node[4]->nn_param.conv2d.dilation[1] = 1;
    node[4]->nn_param.conv2d.multiplier = 1;
    node[4]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[4]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[4]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_75
      var       - node[5]
      name      - MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D
      operation - convolution
      input     - [56, 56, 64, 1]
      filter    - [1, 1, 64, 128]
      output    - [56, 56, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[5], VSI_NN_OP_CONV2D, 3, 1, 75);
    node[5]->nn_param.conv2d.ksize[0] = 1;
    node[5]->nn_param.conv2d.ksize[1] = 1;
    node[5]->nn_param.conv2d.weights = 128;
    node[5]->nn_param.conv2d.stride[0] = 1;
    node[5]->nn_param.conv2d.stride[1] = 1;
    node[5]->nn_param.conv2d.pad[0] = 0;
    node[5]->nn_param.conv2d.pad[1] = 0;
    node[5]->nn_param.conv2d.pad[2] = 0;
    node[5]->nn_param.conv2d.pad[3] = 0;
    node[5]->nn_param.conv2d.group = 1;
    node[5]->nn_param.conv2d.dilation[0] = 1;
    node[5]->nn_param.conv2d.dilation[1] = 1;
    node[5]->nn_param.conv2d.multiplier = 0;
    node[5]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[5]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[5]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_3_depthwise/depthwise_72
      var       - node[6]
      name      - MobilenetV1/MobilenetV1/Conv2d_3_depthwise/depthwise
      operation - convolution
      input     - [56, 56, 128, 1]
      filter    - [3, 3, 128, 1]
      output    - [56, 56, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[6], VSI_NN_OP_CONV2D, 3, 1, 72);
    node[6]->nn_param.conv2d.ksize[0] = 3;
    node[6]->nn_param.conv2d.ksize[1] = 3;
    node[6]->nn_param.conv2d.weights = 128;
    node[6]->nn_param.conv2d.stride[0] = 1;
    node[6]->nn_param.conv2d.stride[1] = 1;
    node[6]->nn_param.conv2d.pad[0] = 1;
    node[6]->nn_param.conv2d.pad[1] = 1;
    node[6]->nn_param.conv2d.pad[2] = 1;
    node[6]->nn_param.conv2d.pad[3] = 1;
    node[6]->nn_param.conv2d.group = 128;
    node[6]->nn_param.conv2d.dilation[0] = 1;
    node[6]->nn_param.conv2d.dilation[1] = 1;
    node[6]->nn_param.conv2d.multiplier = 1;
    node[6]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[6]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[6]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_69
      var       - node[7]
      name      - MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D
      operation - convolution
      input     - [56, 56, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [56, 56, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[7], VSI_NN_OP_CONV2D, 3, 1, 69);
    node[7]->nn_param.conv2d.ksize[0] = 1;
    node[7]->nn_param.conv2d.ksize[1] = 1;
    node[7]->nn_param.conv2d.weights = 128;
    node[7]->nn_param.conv2d.stride[0] = 1;
    node[7]->nn_param.conv2d.stride[1] = 1;
    node[7]->nn_param.conv2d.pad[0] = 0;
    node[7]->nn_param.conv2d.pad[1] = 0;
    node[7]->nn_param.conv2d.pad[2] = 0;
    node[7]->nn_param.conv2d.pad[3] = 0;
    node[7]->nn_param.conv2d.group = 1;
    node[7]->nn_param.conv2d.dilation[0] = 1;
    node[7]->nn_param.conv2d.dilation[1] = 1;
    node[7]->nn_param.conv2d.multiplier = 0;
    node[7]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[7]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[7]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_4_depthwise/depthwise_66
      var       - node[8]
      name      - MobilenetV1/MobilenetV1/Conv2d_4_depthwise/depthwise
      operation - convolution
      input     - [56, 56, 128, 1]
      filter    - [3, 3, 128, 1]
      output    - [28, 28, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[8], VSI_NN_OP_CONV2D, 3, 1, 66);
    node[8]->nn_param.conv2d.ksize[0] = 3;
    node[8]->nn_param.conv2d.ksize[1] = 3;
    node[8]->nn_param.conv2d.weights = 128;
    node[8]->nn_param.conv2d.stride[0] = 2;
    node[8]->nn_param.conv2d.stride[1] = 2;
    node[8]->nn_param.conv2d.pad[0] = 0;
    node[8]->nn_param.conv2d.pad[1] = 1;
    node[8]->nn_param.conv2d.pad[2] = 0;
    node[8]->nn_param.conv2d.pad[3] = 1;
    node[8]->nn_param.conv2d.group = 128;
    node[8]->nn_param.conv2d.dilation[0] = 1;
    node[8]->nn_param.conv2d.dilation[1] = 1;
    node[8]->nn_param.conv2d.multiplier = 1;
    node[8]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[8]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[8]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_63
      var       - node[9]
      name      - MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D
      operation - convolution
      input     - [28, 28, 128, 1]
      filter    - [1, 1, 128, 256]
      output    - [28, 28, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[9], VSI_NN_OP_CONV2D, 3, 1, 63);
    node[9]->nn_param.conv2d.ksize[0] = 1;
    node[9]->nn_param.conv2d.ksize[1] = 1;
    node[9]->nn_param.conv2d.weights = 256;
    node[9]->nn_param.conv2d.stride[0] = 1;
    node[9]->nn_param.conv2d.stride[1] = 1;
    node[9]->nn_param.conv2d.pad[0] = 0;
    node[9]->nn_param.conv2d.pad[1] = 0;
    node[9]->nn_param.conv2d.pad[2] = 0;
    node[9]->nn_param.conv2d.pad[3] = 0;
    node[9]->nn_param.conv2d.group = 1;
    node[9]->nn_param.conv2d.dilation[0] = 1;
    node[9]->nn_param.conv2d.dilation[1] = 1;
    node[9]->nn_param.conv2d.multiplier = 0;
    node[9]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[9]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[9]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_5_depthwise/depthwise_60
      var       - node[10]
      name      - MobilenetV1/MobilenetV1/Conv2d_5_depthwise/depthwise
      operation - convolution
      input     - [28, 28, 256, 1]
      filter    - [3, 3, 256, 1]
      output    - [28, 28, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[10], VSI_NN_OP_CONV2D, 3, 1, 60);
    node[10]->nn_param.conv2d.ksize[0] = 3;
    node[10]->nn_param.conv2d.ksize[1] = 3;
    node[10]->nn_param.conv2d.weights = 256;
    node[10]->nn_param.conv2d.stride[0] = 1;
    node[10]->nn_param.conv2d.stride[1] = 1;
    node[10]->nn_param.conv2d.pad[0] = 1;
    node[10]->nn_param.conv2d.pad[1] = 1;
    node[10]->nn_param.conv2d.pad[2] = 1;
    node[10]->nn_param.conv2d.pad[3] = 1;
    node[10]->nn_param.conv2d.group = 256;
    node[10]->nn_param.conv2d.dilation[0] = 1;
    node[10]->nn_param.conv2d.dilation[1] = 1;
    node[10]->nn_param.conv2d.multiplier = 1;
    node[10]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[10]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[10]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_57
      var       - node[11]
      name      - MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D
      operation - convolution
      input     - [28, 28, 256, 1]
      filter    - [1, 1, 256, 256]
      output    - [28, 28, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[11], VSI_NN_OP_CONV2D, 3, 1, 57);
    node[11]->nn_param.conv2d.ksize[0] = 1;
    node[11]->nn_param.conv2d.ksize[1] = 1;
    node[11]->nn_param.conv2d.weights = 256;
    node[11]->nn_param.conv2d.stride[0] = 1;
    node[11]->nn_param.conv2d.stride[1] = 1;
    node[11]->nn_param.conv2d.pad[0] = 0;
    node[11]->nn_param.conv2d.pad[1] = 0;
    node[11]->nn_param.conv2d.pad[2] = 0;
    node[11]->nn_param.conv2d.pad[3] = 0;
    node[11]->nn_param.conv2d.group = 1;
    node[11]->nn_param.conv2d.dilation[0] = 1;
    node[11]->nn_param.conv2d.dilation[1] = 1;
    node[11]->nn_param.conv2d.multiplier = 0;
    node[11]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[11]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[11]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_6_depthwise/depthwise_54
      var       - node[12]
      name      - MobilenetV1/MobilenetV1/Conv2d_6_depthwise/depthwise
      operation - convolution
      input     - [28, 28, 256, 1]
      filter    - [3, 3, 256, 1]
      output    - [14, 14, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[12], VSI_NN_OP_CONV2D, 3, 1, 54);
    node[12]->nn_param.conv2d.ksize[0] = 3;
    node[12]->nn_param.conv2d.ksize[1] = 3;
    node[12]->nn_param.conv2d.weights = 256;
    node[12]->nn_param.conv2d.stride[0] = 2;
    node[12]->nn_param.conv2d.stride[1] = 2;
    node[12]->nn_param.conv2d.pad[0] = 0;
    node[12]->nn_param.conv2d.pad[1] = 1;
    node[12]->nn_param.conv2d.pad[2] = 0;
    node[12]->nn_param.conv2d.pad[3] = 1;
    node[12]->nn_param.conv2d.group = 256;
    node[12]->nn_param.conv2d.dilation[0] = 1;
    node[12]->nn_param.conv2d.dilation[1] = 1;
    node[12]->nn_param.conv2d.multiplier = 1;
    node[12]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[12]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[12]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_51
      var       - node[13]
      name      - MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D
      operation - convolution
      input     - [14, 14, 256, 1]
      filter    - [1, 1, 256, 512]
      output    - [14, 14, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[13], VSI_NN_OP_CONV2D, 3, 1, 51);
    node[13]->nn_param.conv2d.ksize[0] = 1;
    node[13]->nn_param.conv2d.ksize[1] = 1;
    node[13]->nn_param.conv2d.weights = 512;
    node[13]->nn_param.conv2d.stride[0] = 1;
    node[13]->nn_param.conv2d.stride[1] = 1;
    node[13]->nn_param.conv2d.pad[0] = 0;
    node[13]->nn_param.conv2d.pad[1] = 0;
    node[13]->nn_param.conv2d.pad[2] = 0;
    node[13]->nn_param.conv2d.pad[3] = 0;
    node[13]->nn_param.conv2d.group = 1;
    node[13]->nn_param.conv2d.dilation[0] = 1;
    node[13]->nn_param.conv2d.dilation[1] = 1;
    node[13]->nn_param.conv2d.multiplier = 0;
    node[13]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[13]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[13]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_7_depthwise/depthwise_48
      var       - node[14]
      name      - MobilenetV1/MobilenetV1/Conv2d_7_depthwise/depthwise
      operation - convolution
      input     - [14, 14, 512, 1]
      filter    - [3, 3, 512, 1]
      output    - [14, 14, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[14], VSI_NN_OP_CONV2D, 3, 1, 48);
    node[14]->nn_param.conv2d.ksize[0] = 3;
    node[14]->nn_param.conv2d.ksize[1] = 3;
    node[14]->nn_param.conv2d.weights = 512;
    node[14]->nn_param.conv2d.stride[0] = 1;
    node[14]->nn_param.conv2d.stride[1] = 1;
    node[14]->nn_param.conv2d.pad[0] = 1;
    node[14]->nn_param.conv2d.pad[1] = 1;
    node[14]->nn_param.conv2d.pad[2] = 1;
    node[14]->nn_param.conv2d.pad[3] = 1;
    node[14]->nn_param.conv2d.group = 512;
    node[14]->nn_param.conv2d.dilation[0] = 1;
    node[14]->nn_param.conv2d.dilation[1] = 1;
    node[14]->nn_param.conv2d.multiplier = 1;
    node[14]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[14]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[14]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_45
      var       - node[15]
      name      - MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D
      operation - convolution
      input     - [14, 14, 512, 1]
      filter    - [1, 1, 512, 512]
      output    - [14, 14, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[15], VSI_NN_OP_CONV2D, 3, 1, 45);
    node[15]->nn_param.conv2d.ksize[0] = 1;
    node[15]->nn_param.conv2d.ksize[1] = 1;
    node[15]->nn_param.conv2d.weights = 512;
    node[15]->nn_param.conv2d.stride[0] = 1;
    node[15]->nn_param.conv2d.stride[1] = 1;
    node[15]->nn_param.conv2d.pad[0] = 0;
    node[15]->nn_param.conv2d.pad[1] = 0;
    node[15]->nn_param.conv2d.pad[2] = 0;
    node[15]->nn_param.conv2d.pad[3] = 0;
    node[15]->nn_param.conv2d.group = 1;
    node[15]->nn_param.conv2d.dilation[0] = 1;
    node[15]->nn_param.conv2d.dilation[1] = 1;
    node[15]->nn_param.conv2d.multiplier = 0;
    node[15]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[15]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[15]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_8_depthwise/depthwise_42
      var       - node[16]
      name      - MobilenetV1/MobilenetV1/Conv2d_8_depthwise/depthwise
      operation - convolution
      input     - [14, 14, 512, 1]
      filter    - [3, 3, 512, 1]
      output    - [14, 14, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[16], VSI_NN_OP_CONV2D, 3, 1, 42);
    node[16]->nn_param.conv2d.ksize[0] = 3;
    node[16]->nn_param.conv2d.ksize[1] = 3;
    node[16]->nn_param.conv2d.weights = 512;
    node[16]->nn_param.conv2d.stride[0] = 1;
    node[16]->nn_param.conv2d.stride[1] = 1;
    node[16]->nn_param.conv2d.pad[0] = 1;
    node[16]->nn_param.conv2d.pad[1] = 1;
    node[16]->nn_param.conv2d.pad[2] = 1;
    node[16]->nn_param.conv2d.pad[3] = 1;
    node[16]->nn_param.conv2d.group = 512;
    node[16]->nn_param.conv2d.dilation[0] = 1;
    node[16]->nn_param.conv2d.dilation[1] = 1;
    node[16]->nn_param.conv2d.multiplier = 1;
    node[16]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[16]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[16]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_39
      var       - node[17]
      name      - MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D
      operation - convolution
      input     - [14, 14, 512, 1]
      filter    - [1, 1, 512, 512]
      output    - [14, 14, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[17], VSI_NN_OP_CONV2D, 3, 1, 39);
    node[17]->nn_param.conv2d.ksize[0] = 1;
    node[17]->nn_param.conv2d.ksize[1] = 1;
    node[17]->nn_param.conv2d.weights = 512;
    node[17]->nn_param.conv2d.stride[0] = 1;
    node[17]->nn_param.conv2d.stride[1] = 1;
    node[17]->nn_param.conv2d.pad[0] = 0;
    node[17]->nn_param.conv2d.pad[1] = 0;
    node[17]->nn_param.conv2d.pad[2] = 0;
    node[17]->nn_param.conv2d.pad[3] = 0;
    node[17]->nn_param.conv2d.group = 1;
    node[17]->nn_param.conv2d.dilation[0] = 1;
    node[17]->nn_param.conv2d.dilation[1] = 1;
    node[17]->nn_param.conv2d.multiplier = 0;
    node[17]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[17]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[17]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_9_depthwise/depthwise_36
      var       - node[18]
      name      - MobilenetV1/MobilenetV1/Conv2d_9_depthwise/depthwise
      operation - convolution
      input     - [14, 14, 512, 1]
      filter    - [3, 3, 512, 1]
      output    - [14, 14, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[18], VSI_NN_OP_CONV2D, 3, 1, 36);
    node[18]->nn_param.conv2d.ksize[0] = 3;
    node[18]->nn_param.conv2d.ksize[1] = 3;
    node[18]->nn_param.conv2d.weights = 512;
    node[18]->nn_param.conv2d.stride[0] = 1;
    node[18]->nn_param.conv2d.stride[1] = 1;
    node[18]->nn_param.conv2d.pad[0] = 1;
    node[18]->nn_param.conv2d.pad[1] = 1;
    node[18]->nn_param.conv2d.pad[2] = 1;
    node[18]->nn_param.conv2d.pad[3] = 1;
    node[18]->nn_param.conv2d.group = 512;
    node[18]->nn_param.conv2d.dilation[0] = 1;
    node[18]->nn_param.conv2d.dilation[1] = 1;
    node[18]->nn_param.conv2d.multiplier = 1;
    node[18]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[18]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[18]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_33
      var       - node[19]
      name      - MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D
      operation - convolution
      input     - [14, 14, 512, 1]
      filter    - [1, 1, 512, 512]
      output    - [14, 14, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[19], VSI_NN_OP_CONV2D, 3, 1, 33);
    node[19]->nn_param.conv2d.ksize[0] = 1;
    node[19]->nn_param.conv2d.ksize[1] = 1;
    node[19]->nn_param.conv2d.weights = 512;
    node[19]->nn_param.conv2d.stride[0] = 1;
    node[19]->nn_param.conv2d.stride[1] = 1;
    node[19]->nn_param.conv2d.pad[0] = 0;
    node[19]->nn_param.conv2d.pad[1] = 0;
    node[19]->nn_param.conv2d.pad[2] = 0;
    node[19]->nn_param.conv2d.pad[3] = 0;
    node[19]->nn_param.conv2d.group = 1;
    node[19]->nn_param.conv2d.dilation[0] = 1;
    node[19]->nn_param.conv2d.dilation[1] = 1;
    node[19]->nn_param.conv2d.multiplier = 0;
    node[19]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[19]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[19]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_10_depthwise/depthwise_30
      var       - node[20]
      name      - MobilenetV1/MobilenetV1/Conv2d_10_depthwise/depthwise
      operation - convolution
      input     - [14, 14, 512, 1]
      filter    - [3, 3, 512, 1]
      output    - [14, 14, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[20], VSI_NN_OP_CONV2D, 3, 1, 30);
    node[20]->nn_param.conv2d.ksize[0] = 3;
    node[20]->nn_param.conv2d.ksize[1] = 3;
    node[20]->nn_param.conv2d.weights = 512;
    node[20]->nn_param.conv2d.stride[0] = 1;
    node[20]->nn_param.conv2d.stride[1] = 1;
    node[20]->nn_param.conv2d.pad[0] = 1;
    node[20]->nn_param.conv2d.pad[1] = 1;
    node[20]->nn_param.conv2d.pad[2] = 1;
    node[20]->nn_param.conv2d.pad[3] = 1;
    node[20]->nn_param.conv2d.group = 512;
    node[20]->nn_param.conv2d.dilation[0] = 1;
    node[20]->nn_param.conv2d.dilation[1] = 1;
    node[20]->nn_param.conv2d.multiplier = 1;
    node[20]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[20]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[20]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_27
      var       - node[21]
      name      - MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D
      operation - convolution
      input     - [14, 14, 512, 1]
      filter    - [1, 1, 512, 512]
      output    - [14, 14, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[21], VSI_NN_OP_CONV2D, 3, 1, 27);
    node[21]->nn_param.conv2d.ksize[0] = 1;
    node[21]->nn_param.conv2d.ksize[1] = 1;
    node[21]->nn_param.conv2d.weights = 512;
    node[21]->nn_param.conv2d.stride[0] = 1;
    node[21]->nn_param.conv2d.stride[1] = 1;
    node[21]->nn_param.conv2d.pad[0] = 0;
    node[21]->nn_param.conv2d.pad[1] = 0;
    node[21]->nn_param.conv2d.pad[2] = 0;
    node[21]->nn_param.conv2d.pad[3] = 0;
    node[21]->nn_param.conv2d.group = 1;
    node[21]->nn_param.conv2d.dilation[0] = 1;
    node[21]->nn_param.conv2d.dilation[1] = 1;
    node[21]->nn_param.conv2d.multiplier = 0;
    node[21]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[21]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[21]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_11_depthwise/depthwise_24
      var       - node[22]
      name      - MobilenetV1/MobilenetV1/Conv2d_11_depthwise/depthwise
      operation - convolution
      input     - [14, 14, 512, 1]
      filter    - [3, 3, 512, 1]
      output    - [14, 14, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[22], VSI_NN_OP_CONV2D, 3, 1, 24);
    node[22]->nn_param.conv2d.ksize[0] = 3;
    node[22]->nn_param.conv2d.ksize[1] = 3;
    node[22]->nn_param.conv2d.weights = 512;
    node[22]->nn_param.conv2d.stride[0] = 1;
    node[22]->nn_param.conv2d.stride[1] = 1;
    node[22]->nn_param.conv2d.pad[0] = 1;
    node[22]->nn_param.conv2d.pad[1] = 1;
    node[22]->nn_param.conv2d.pad[2] = 1;
    node[22]->nn_param.conv2d.pad[3] = 1;
    node[22]->nn_param.conv2d.group = 512;
    node[22]->nn_param.conv2d.dilation[0] = 1;
    node[22]->nn_param.conv2d.dilation[1] = 1;
    node[22]->nn_param.conv2d.multiplier = 1;
    node[22]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[22]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[22]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_21
      var       - node[23]
      name      - MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D
      operation - convolution
      input     - [14, 14, 512, 1]
      filter    - [1, 1, 512, 512]
      output    - [14, 14, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[23], VSI_NN_OP_CONV2D, 3, 1, 21);
    node[23]->nn_param.conv2d.ksize[0] = 1;
    node[23]->nn_param.conv2d.ksize[1] = 1;
    node[23]->nn_param.conv2d.weights = 512;
    node[23]->nn_param.conv2d.stride[0] = 1;
    node[23]->nn_param.conv2d.stride[1] = 1;
    node[23]->nn_param.conv2d.pad[0] = 0;
    node[23]->nn_param.conv2d.pad[1] = 0;
    node[23]->nn_param.conv2d.pad[2] = 0;
    node[23]->nn_param.conv2d.pad[3] = 0;
    node[23]->nn_param.conv2d.group = 1;
    node[23]->nn_param.conv2d.dilation[0] = 1;
    node[23]->nn_param.conv2d.dilation[1] = 1;
    node[23]->nn_param.conv2d.multiplier = 0;
    node[23]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[23]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[23]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_12_depthwise/depthwise_18
      var       - node[24]
      name      - MobilenetV1/MobilenetV1/Conv2d_12_depthwise/depthwise
      operation - convolution
      input     - [14, 14, 512, 1]
      filter    - [3, 3, 512, 1]
      output    - [7, 7, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[24], VSI_NN_OP_CONV2D, 3, 1, 18);
    node[24]->nn_param.conv2d.ksize[0] = 3;
    node[24]->nn_param.conv2d.ksize[1] = 3;
    node[24]->nn_param.conv2d.weights = 512;
    node[24]->nn_param.conv2d.stride[0] = 2;
    node[24]->nn_param.conv2d.stride[1] = 2;
    node[24]->nn_param.conv2d.pad[0] = 0;
    node[24]->nn_param.conv2d.pad[1] = 1;
    node[24]->nn_param.conv2d.pad[2] = 0;
    node[24]->nn_param.conv2d.pad[3] = 1;
    node[24]->nn_param.conv2d.group = 512;
    node[24]->nn_param.conv2d.dilation[0] = 1;
    node[24]->nn_param.conv2d.dilation[1] = 1;
    node[24]->nn_param.conv2d.multiplier = 1;
    node[24]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[24]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[24]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_15
      var       - node[25]
      name      - MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D
      operation - convolution
      input     - [7, 7, 512, 1]
      filter    - [1, 1, 512, 1024]
      output    - [7, 7, 1024, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[25], VSI_NN_OP_CONV2D, 3, 1, 15);
    node[25]->nn_param.conv2d.ksize[0] = 1;
    node[25]->nn_param.conv2d.ksize[1] = 1;
    node[25]->nn_param.conv2d.weights = 1024;
    node[25]->nn_param.conv2d.stride[0] = 1;
    node[25]->nn_param.conv2d.stride[1] = 1;
    node[25]->nn_param.conv2d.pad[0] = 0;
    node[25]->nn_param.conv2d.pad[1] = 0;
    node[25]->nn_param.conv2d.pad[2] = 0;
    node[25]->nn_param.conv2d.pad[3] = 0;
    node[25]->nn_param.conv2d.group = 1;
    node[25]->nn_param.conv2d.dilation[0] = 1;
    node[25]->nn_param.conv2d.dilation[1] = 1;
    node[25]->nn_param.conv2d.multiplier = 0;
    node[25]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[25]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[25]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_13_depthwise/depthwise_12
      var       - node[26]
      name      - MobilenetV1/MobilenetV1/Conv2d_13_depthwise/depthwise
      operation - convolution
      input     - [7, 7, 1024, 1]
      filter    - [3, 3, 1024, 1]
      output    - [7, 7, 1024, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[26], VSI_NN_OP_CONV2D, 3, 1, 12);
    node[26]->nn_param.conv2d.ksize[0] = 3;
    node[26]->nn_param.conv2d.ksize[1] = 3;
    node[26]->nn_param.conv2d.weights = 1024;
    node[26]->nn_param.conv2d.stride[0] = 1;
    node[26]->nn_param.conv2d.stride[1] = 1;
    node[26]->nn_param.conv2d.pad[0] = 1;
    node[26]->nn_param.conv2d.pad[1] = 1;
    node[26]->nn_param.conv2d.pad[2] = 1;
    node[26]->nn_param.conv2d.pad[3] = 1;
    node[26]->nn_param.conv2d.group = 1024;
    node[26]->nn_param.conv2d.dilation[0] = 1;
    node[26]->nn_param.conv2d.dilation[1] = 1;
    node[26]->nn_param.conv2d.multiplier = 1;
    node[26]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[26]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[26]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_9
      var       - node[27]
      name      - MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D
      operation - convolution
      input     - [7, 7, 1024, 1]
      filter    - [1, 1, 1024, 1024]
      output    - [7, 7, 1024, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[27], VSI_NN_OP_CONV2D, 3, 1, 9);
    node[27]->nn_param.conv2d.ksize[0] = 1;
    node[27]->nn_param.conv2d.ksize[1] = 1;
    node[27]->nn_param.conv2d.weights = 1024;
    node[27]->nn_param.conv2d.stride[0] = 1;
    node[27]->nn_param.conv2d.stride[1] = 1;
    node[27]->nn_param.conv2d.pad[0] = 0;
    node[27]->nn_param.conv2d.pad[1] = 0;
    node[27]->nn_param.conv2d.pad[2] = 0;
    node[27]->nn_param.conv2d.pad[3] = 0;
    node[27]->nn_param.conv2d.group = 1;
    node[27]->nn_param.conv2d.dilation[0] = 1;
    node[27]->nn_param.conv2d.dilation[1] = 1;
    node[27]->nn_param.conv2d.multiplier = 0;
    node[27]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[27]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[27]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/Logits/AvgPool_1a/AvgPool_6
      var       - node[28]
      name      - MobilenetV1/Logits/AvgPool_1a/AvgPool
      operation - pooling
      input     - [7, 7, 1024, 1]
      output    - [1, 1, 1024, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[28], VSI_NN_OP_POOL, 1, 1, 6);
    node[28]->nn_param.pool.ksize[0] = 7;
    node[28]->nn_param.pool.ksize[1] = 7;
    node[28]->nn_param.pool.stride[0] = 2;
    node[28]->nn_param.pool.stride[1] = 2;
    node[28]->nn_param.pool.pad[0] = 0;
    node[28]->nn_param.pool.pad[1] = 0;
    node[28]->nn_param.pool.pad[2] = 0;
    node[28]->nn_param.pool.pad[3] = 0;
    node[28]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG_ANDROID;
    node[28]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[28]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd_5
      var       - node[29]
      name      - MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd
      operation - convolution
      input     - [1, 1, 1024, 1]
      filter    - [1, 1, 1024, 1001]
      output    - [1, 1, 1001, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[29], VSI_NN_OP_CONV2D, 3, 1, 5);
    node[29]->nn_param.conv2d.ksize[0] = 1;
    node[29]->nn_param.conv2d.ksize[1] = 1;
    node[29]->nn_param.conv2d.weights = 1001;
    node[29]->nn_param.conv2d.stride[0] = 1;
    node[29]->nn_param.conv2d.stride[1] = 1;
    node[29]->nn_param.conv2d.pad[0] = 0;
    node[29]->nn_param.conv2d.pad[1] = 0;
    node[29]->nn_param.conv2d.pad[2] = 0;
    node[29]->nn_param.conv2d.pad[3] = 0;
    node[29]->nn_param.conv2d.group = 1;
    node[29]->nn_param.conv2d.dilation[0] = 1;
    node[29]->nn_param.conv2d.dilation[1] = 1;
    node[29]->nn_param.conv2d.multiplier = 0;
    node[29]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[29]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[29]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MobilenetV1/Logits/SpatialSqueeze_4_acuity_mark_perm_11
      var       - node[30]
      name      - MobilenetV1/Logits/SpatialSqueeze_4_acuity_mark_perm
      operation - permute
      input     - [1, 1, 1001, 1]
      output    - [1001, 1, 1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[30], VSI_NN_OP_PERMUTE, 1, 1, 11);
    node[30]->nn_param.permute.perm = perm_2;
    node[30]->nn_param.permute.dim_num = 4;

    /*-----------------------------------------
      lid       - MobilenetV1/Logits/SpatialSqueeze_4
      var       - node[31]
      name      - MobilenetV1/Logits/SpatialSqueeze
      operation - reshape
      input     - [1001, 1, 1, 1]
      output    - [1001, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[31], VSI_NN_OP_RESHAPE, 1, 1, 4);
    node[31]->nn_param.reshape.size = shape_1;
    node[31]->nn_param.reshape.dim_num = 2;

    /*-----------------------------------------
      lid       - MobilenetV1/Predictions/Softmax_2
      var       - node[32]
      name      - MobilenetV1/Predictions/Softmax
      operation - softmax
      input     - [1001, 1]
      output    - [1001, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[32], VSI_NN_OP_SOFTMAX, 1, 1, 2);
    node[32]->nn_param.softmax.beta = 1.0;
    node[32]->nn_param.softmax.axis = 0;


/*-----------------------------------------
  Tensor initialize
 -----------------------------------------*/
    attr.dtype.fmt = VSI_NN_DIM_FMT_NCHW;
    /* @attach_MobilenetV1/Predictions/Softmax/out0_0:out0 */
    attr.size[0] = 1001;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_NORM_TENSOR(norm_tensor[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @attach_input/out0_1:out0 */
    attr.size[0] = 3;
    attr.size[1] = 224;
    attr.size[2] = 224;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0078125;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[1], attr, VSI_NN_TYPE_UINT8);



    /* @MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_87:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 3;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.019131295382976532;
    attr.dtype.zero_point = 148;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[0], attr, VSI_NN_TYPE_UINT8, 1029156, 864);

    /* @MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_87:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00014946324517950416;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[1], attr, VSI_NN_TYPE_INT32, 1029028, 128);

    /* @MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise_84:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.028076814487576485;
    attr.dtype.zero_point = 120;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[2], attr, VSI_NN_TYPE_UINT8, 3172868, 288);

    /* @MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise_84:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0006606309420399172;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[3], attr, VSI_NN_TYPE_INT32, 3172740, 128);

    /* @MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_81:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 32;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.032475609332323074;
    attr.dtype.zero_point = 126;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[4], attr, VSI_NN_TYPE_UINT8, 3173412, 2048);

    /* @MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_81:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0007641319992346754;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[5], attr, VSI_NN_TYPE_INT32, 3173156, 256);

    /* @MobilenetV1/MobilenetV1/Conv2d_2_depthwise/depthwise_78:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.03641602396965027;
    attr.dtype.zero_point = 126;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[6], attr, VSI_NN_TYPE_UINT8, 3175716, 576);

    /* @MobilenetV1/MobilenetV1/Conv2d_2_depthwise/depthwise_78:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0008568476395733327;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[7], attr, VSI_NN_TYPE_INT32, 3175460, 256);

    /* @MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_75:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.016863998025655746;
    attr.dtype.zero_point = 104;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[8], attr, VSI_NN_TYPE_UINT8, 3176804, 8192);

    /* @MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_75:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00039679996130536493;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[9], attr, VSI_NN_TYPE_INT32, 3176292, 512);

    /* @MobilenetV1/MobilenetV1/Conv2d_3_depthwise/depthwise_72:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.07136167585849762;
    attr.dtype.zero_point = 152;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[10], attr, VSI_NN_TYPE_UINT8, 3185508, 1152);

    /* @MobilenetV1/MobilenetV1/Conv2d_3_depthwise/depthwise_72:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.001679098288333486;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[11], attr, VSI_NN_TYPE_INT32, 3184996, 512);

    /* @MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_69:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.013668297789990902;
    attr.dtype.zero_point = 92;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[12], attr, VSI_NN_TYPE_UINT8, 3187172, 16384);

    /* @MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_69:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0003216070131132325;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[13], attr, VSI_NN_TYPE_INT32, 3186660, 512);

    /* @MobilenetV1/MobilenetV1/Conv2d_4_depthwise/depthwise_66:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.01665486954152584;
    attr.dtype.zero_point = 121;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[14], attr, VSI_NN_TYPE_UINT8, 3204068, 1152);

    /* @MobilenetV1/MobilenetV1/Conv2d_4_depthwise/depthwise_66:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00039187929099430627;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[15], attr, VSI_NN_TYPE_INT32, 3203556, 512);

    /* @MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_63:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007539772428572178;
    attr.dtype.zero_point = 153;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[16], attr, VSI_NN_TYPE_UINT8, 3206244, 32768);

    /* @MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_63:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00017740641355372573;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[17], attr, VSI_NN_TYPE_INT32, 3205220, 1024);

    /* @MobilenetV1/MobilenetV1/Conv2d_5_depthwise/depthwise_60:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 256;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.041016172617673874;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[18], attr, VSI_NN_TYPE_UINT8, 3240036, 2304);

    /* @MobilenetV1/MobilenetV1/Conv2d_5_depthwise/depthwise_60:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.000965086433408445;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[19], attr, VSI_NN_TYPE_INT32, 3239012, 1024);

    /* @MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_57:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.006381323095411062;
    attr.dtype.zero_point = 120;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[20], attr, VSI_NN_TYPE_UINT8, 3243364, 65536);

    /* @MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_57:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001501487816521303;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[21], attr, VSI_NN_TYPE_INT32, 3242340, 1024);

    /* @MobilenetV1/MobilenetV1/Conv2d_6_depthwise/depthwise_54:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 256;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.013540172949433327;
    attr.dtype.zero_point = 121;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[22], attr, VSI_NN_TYPE_UINT8, 3309924, 2304);

    /* @MobilenetV1/MobilenetV1/Conv2d_6_depthwise/depthwise_54:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0003185923109235052;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[23], attr, VSI_NN_TYPE_INT32, 3308900, 1024);

    /* @MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_51:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.009132234379649162;
    attr.dtype.zero_point = 109;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[24], attr, VSI_NN_TYPE_UINT8, 3314276, 131072);

    /* @MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_51:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002148761072530668;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[25], attr, VSI_NN_TYPE_INT32, 3312228, 2048);

    /* @MobilenetV1/MobilenetV1/Conv2d_7_depthwise/depthwise_48:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 512;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.03683149442076683;
    attr.dtype.zero_point = 130;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[26], attr, VSI_NN_TYPE_UINT8, 3447396, 4608);

    /* @MobilenetV1/MobilenetV1/Conv2d_7_depthwise/depthwise_48:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0008666234150849147;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[27], attr, VSI_NN_TYPE_INT32, 3445348, 2048);

    /* @MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_45:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.005361382383853197;
    attr.dtype.zero_point = 141;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[28], attr, VSI_NN_TYPE_UINT8, 3454052, 262144);

    /* @MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_45:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00012615017620493888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[29], attr, VSI_NN_TYPE_INT32, 3452004, 2048);

    /* @MobilenetV1/MobilenetV1/Conv2d_8_depthwise/depthwise_42:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 512;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.04294472560286522;
    attr.dtype.zero_point = 94;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[30], attr, VSI_NN_TYPE_UINT8, 3718244, 4608);

    /* @MobilenetV1/MobilenetV1/Conv2d_8_depthwise/depthwise_42:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0009422567292877299;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[31], attr, VSI_NN_TYPE_INT32, 3716196, 2048);

    /* @MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_39:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0049892608076334;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[32], attr, VSI_NN_TYPE_UINT8, 3724900, 262144);

    /* @MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_39:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001173943742402879;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[33], attr, VSI_NN_TYPE_INT32, 3722852, 2048);

    /* @MobilenetV1/MobilenetV1/Conv2d_9_depthwise/depthwise_36:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 512;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.028366895392537117;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[34], attr, VSI_NN_TYPE_UINT8, 3989092, 4608);

    /* @MobilenetV1/MobilenetV1/Conv2d_9_depthwise/depthwise_36:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0006269933426105399;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[35], attr, VSI_NN_TYPE_INT32, 3987044, 2048);

    /* @MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_33:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00782010704278946;
    attr.dtype.zero_point = 88;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[36], attr, VSI_NN_TYPE_UINT8, 3995748, 262144);

    /* @MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_33:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00018400252225254932;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[37], attr, VSI_NN_TYPE_INT32, 3993700, 2048);

    /* @MobilenetV1/MobilenetV1/Conv2d_10_depthwise/depthwise_30:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 512;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.024905357509851456;
    attr.dtype.zero_point = 136;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[38], attr, VSI_NN_TYPE_UINT8, 1032068, 4608);

    /* @MobilenetV1/MobilenetV1/Conv2d_10_depthwise/depthwise_30:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.000586008423457525;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[39], attr, VSI_NN_TYPE_INT32, 1030020, 2048);

    /* @MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_27:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.009593848139047623;
    attr.dtype.zero_point = 99;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[40], attr, VSI_NN_TYPE_UINT8, 1038724, 262144);

    /* @MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_27:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002257376076866338;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[41], attr, VSI_NN_TYPE_INT32, 1036676, 2048);

    /* @MobilenetV1/MobilenetV1/Conv2d_11_depthwise/depthwise_24:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 512;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.01952832192182541;
    attr.dtype.zero_point = 105;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[42], attr, VSI_NN_TYPE_UINT8, 1302916, 4608);

    /* @MobilenetV1/MobilenetV1/Conv2d_11_depthwise/depthwise_24:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00045948993655896275;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[43], attr, VSI_NN_TYPE_INT32, 1300868, 2048);

    /* @MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_21:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00541162583976984;
    attr.dtype.zero_point = 153;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[44], attr, VSI_NN_TYPE_UINT8, 1309572, 262144);

    /* @MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_21:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001273323751908046;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[45], attr, VSI_NN_TYPE_INT32, 1307524, 2048);

    /* @MobilenetV1/MobilenetV1/Conv2d_12_depthwise/depthwise_18:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 512;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007725437171757221;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[46], attr, VSI_NN_TYPE_UINT8, 1573764, 4608);

    /* @MobilenetV1/MobilenetV1/Conv2d_12_depthwise/depthwise_18:bias */
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00018177499583175473;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[47], attr, VSI_NN_TYPE_INT32, 1571716, 2048);

    /* @MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_15:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 1024;
    attr.dim_num = 4;
    attr.dtype.scale = 0.008157572709023952;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[48], attr, VSI_NN_TYPE_UINT8, 1582468, 524288);

    /* @MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_15:bias */
    attr.size[0] = 1024;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00019194289102512745;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[49], attr, VSI_NN_TYPE_INT32, 1578372, 4096);

    /* @MobilenetV1/MobilenetV1/Conv2d_13_depthwise/depthwise_12:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 1024;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.1237042173743248;
    attr.dtype.zero_point = 208;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[50], attr, VSI_NN_TYPE_UINT8, 2110852, 9216);

    /* @MobilenetV1/MobilenetV1/Conv2d_13_depthwise/depthwise_12:bias */
    attr.size[0] = 1024;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0029106875245577396;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[51], attr, VSI_NN_TYPE_INT32, 2106756, 4096);

    /* @MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_9:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 1024;
    attr.dim_num = 4;
    attr.dtype.scale = 0.017925554886460304;
    attr.dtype.zero_point = 95;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[52], attr, VSI_NN_TYPE_UINT8, 2124164, 1048576);

    /* @MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_9:bias */
    attr.size[0] = 1024;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0004217777702833943;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[53], attr, VSI_NN_TYPE_INT32, 2120068, 4096);

    /* @MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd_5:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 1001;
    attr.dim_num = 4;
    attr.dtype.scale = 0.004945995286107063;
    attr.dtype.zero_point = 74;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[54], attr, VSI_NN_TYPE_UINT8, 4004, 1025024);

    /* @MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd_5:bias */
    attr.size[0] = 1001;
    attr.dim_num = 1;
    attr.dtype.scale = 9.236079360378305e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[55], attr, VSI_NN_TYPE_INT32, 0, 4004);



    /* @MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_87_acuity_mark_perm_8:out0 */
    attr.dtype.scale = 0.0078125;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[0]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_87:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[1]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise_84:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[2]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_81:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[3]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_2_depthwise/depthwise_78:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[4]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_75:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[5]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_3_depthwise/depthwise_72:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[6]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_69:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[7]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_4_depthwise/depthwise_66:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[8]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_63:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[9]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_5_depthwise/depthwise_60:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[10]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_57:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[11]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_6_depthwise/depthwise_54:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[12]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_51:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[13]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_7_depthwise/depthwise_48:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[14]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_45:out0 */
    attr.dtype.scale = 0.021941151469945908;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[15]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_8_depthwise/depthwise_42:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[16]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_39:out0 */
    attr.dtype.scale = 0.022102994844317436;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[17]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_9_depthwise/depthwise_36:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[18]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_33:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[19]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_10_depthwise/depthwise_30:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[20]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_27:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[21]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_11_depthwise/depthwise_24:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[22]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_21:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[23]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_12_depthwise/depthwise_18:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[24]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_15:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[25]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_13_depthwise/depthwise_12:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[26]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_9:out0 */
    attr.dtype.scale = 0.0235294122248888;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[27]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/Logits/AvgPool_1a/AvgPool_6:out0 */
    attr.dtype.scale = 0.01867385394871235;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[28]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd_5:out0 */
    attr.dtype.scale = 0.11274140328168869;
    attr.dtype.zero_point = 80;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[29]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/Logits/SpatialSqueeze_4_acuity_mark_perm_11:out0 */
    attr.dtype.scale = 0.11274140328168869;
    attr.dtype.zero_point = 80;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[30]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MobilenetV1/Logits/SpatialSqueeze_4:out0 */
    attr.dtype.scale = 0.11274140328168869;
    attr.dtype.zero_point = 80;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[31]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);



/*-----------------------------------------
  Connection initialize
 -----------------------------------------*/
    node[0]->input.tensors[0] = norm_tensor[1];
    node[32]->output.tensors[0] = norm_tensor[0];

    /* MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_87_acuity_mark_perm_8 */

    /* MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_87 */
    node[1]->input.tensors[0] = node[0]->output.tensors[0];
    node[1]->input.tensors[1] = const_tensor[0]; /* data_weight */
    node[1]->input.tensors[2] = const_tensor[1]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise_84 */
    node[2]->input.tensors[0] = node[1]->output.tensors[0];
    node[2]->input.tensors[1] = const_tensor[2]; /* data_weight */
    node[2]->input.tensors[2] = const_tensor[3]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_81 */
    node[3]->input.tensors[0] = node[2]->output.tensors[0];
    node[3]->input.tensors[1] = const_tensor[4]; /* data_weight */
    node[3]->input.tensors[2] = const_tensor[5]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_2_depthwise/depthwise_78 */
    node[4]->input.tensors[0] = node[3]->output.tensors[0];
    node[4]->input.tensors[1] = const_tensor[6]; /* data_weight */
    node[4]->input.tensors[2] = const_tensor[7]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_75 */
    node[5]->input.tensors[0] = node[4]->output.tensors[0];
    node[5]->input.tensors[1] = const_tensor[8]; /* data_weight */
    node[5]->input.tensors[2] = const_tensor[9]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_3_depthwise/depthwise_72 */
    node[6]->input.tensors[0] = node[5]->output.tensors[0];
    node[6]->input.tensors[1] = const_tensor[10]; /* data_weight */
    node[6]->input.tensors[2] = const_tensor[11]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_69 */
    node[7]->input.tensors[0] = node[6]->output.tensors[0];
    node[7]->input.tensors[1] = const_tensor[12]; /* data_weight */
    node[7]->input.tensors[2] = const_tensor[13]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_4_depthwise/depthwise_66 */
    node[8]->input.tensors[0] = node[7]->output.tensors[0];
    node[8]->input.tensors[1] = const_tensor[14]; /* data_weight */
    node[8]->input.tensors[2] = const_tensor[15]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_63 */
    node[9]->input.tensors[0] = node[8]->output.tensors[0];
    node[9]->input.tensors[1] = const_tensor[16]; /* data_weight */
    node[9]->input.tensors[2] = const_tensor[17]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_5_depthwise/depthwise_60 */
    node[10]->input.tensors[0] = node[9]->output.tensors[0];
    node[10]->input.tensors[1] = const_tensor[18]; /* data_weight */
    node[10]->input.tensors[2] = const_tensor[19]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_57 */
    node[11]->input.tensors[0] = node[10]->output.tensors[0];
    node[11]->input.tensors[1] = const_tensor[20]; /* data_weight */
    node[11]->input.tensors[2] = const_tensor[21]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_6_depthwise/depthwise_54 */
    node[12]->input.tensors[0] = node[11]->output.tensors[0];
    node[12]->input.tensors[1] = const_tensor[22]; /* data_weight */
    node[12]->input.tensors[2] = const_tensor[23]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_51 */
    node[13]->input.tensors[0] = node[12]->output.tensors[0];
    node[13]->input.tensors[1] = const_tensor[24]; /* data_weight */
    node[13]->input.tensors[2] = const_tensor[25]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_7_depthwise/depthwise_48 */
    node[14]->input.tensors[0] = node[13]->output.tensors[0];
    node[14]->input.tensors[1] = const_tensor[26]; /* data_weight */
    node[14]->input.tensors[2] = const_tensor[27]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_45 */
    node[15]->input.tensors[0] = node[14]->output.tensors[0];
    node[15]->input.tensors[1] = const_tensor[28]; /* data_weight */
    node[15]->input.tensors[2] = const_tensor[29]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_8_depthwise/depthwise_42 */
    node[16]->input.tensors[0] = node[15]->output.tensors[0];
    node[16]->input.tensors[1] = const_tensor[30]; /* data_weight */
    node[16]->input.tensors[2] = const_tensor[31]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_39 */
    node[17]->input.tensors[0] = node[16]->output.tensors[0];
    node[17]->input.tensors[1] = const_tensor[32]; /* data_weight */
    node[17]->input.tensors[2] = const_tensor[33]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_9_depthwise/depthwise_36 */
    node[18]->input.tensors[0] = node[17]->output.tensors[0];
    node[18]->input.tensors[1] = const_tensor[34]; /* data_weight */
    node[18]->input.tensors[2] = const_tensor[35]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_33 */
    node[19]->input.tensors[0] = node[18]->output.tensors[0];
    node[19]->input.tensors[1] = const_tensor[36]; /* data_weight */
    node[19]->input.tensors[2] = const_tensor[37]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_10_depthwise/depthwise_30 */
    node[20]->input.tensors[0] = node[19]->output.tensors[0];
    node[20]->input.tensors[1] = const_tensor[38]; /* data_weight */
    node[20]->input.tensors[2] = const_tensor[39]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_27 */
    node[21]->input.tensors[0] = node[20]->output.tensors[0];
    node[21]->input.tensors[1] = const_tensor[40]; /* data_weight */
    node[21]->input.tensors[2] = const_tensor[41]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_11_depthwise/depthwise_24 */
    node[22]->input.tensors[0] = node[21]->output.tensors[0];
    node[22]->input.tensors[1] = const_tensor[42]; /* data_weight */
    node[22]->input.tensors[2] = const_tensor[43]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_21 */
    node[23]->input.tensors[0] = node[22]->output.tensors[0];
    node[23]->input.tensors[1] = const_tensor[44]; /* data_weight */
    node[23]->input.tensors[2] = const_tensor[45]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_12_depthwise/depthwise_18 */
    node[24]->input.tensors[0] = node[23]->output.tensors[0];
    node[24]->input.tensors[1] = const_tensor[46]; /* data_weight */
    node[24]->input.tensors[2] = const_tensor[47]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_15 */
    node[25]->input.tensors[0] = node[24]->output.tensors[0];
    node[25]->input.tensors[1] = const_tensor[48]; /* data_weight */
    node[25]->input.tensors[2] = const_tensor[49]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_13_depthwise/depthwise_12 */
    node[26]->input.tensors[0] = node[25]->output.tensors[0];
    node[26]->input.tensors[1] = const_tensor[50]; /* data_weight */
    node[26]->input.tensors[2] = const_tensor[51]; /* data_bias */

    /* MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_9 */
    node[27]->input.tensors[0] = node[26]->output.tensors[0];
    node[27]->input.tensors[1] = const_tensor[52]; /* data_weight */
    node[27]->input.tensors[2] = const_tensor[53]; /* data_bias */

    /* MobilenetV1/Logits/AvgPool_1a/AvgPool_6 */
    node[28]->input.tensors[0] = node[27]->output.tensors[0];

    /* MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd_5 */
    node[29]->input.tensors[0] = node[28]->output.tensors[0];
    node[29]->input.tensors[1] = const_tensor[54]; /* data_weight */
    node[29]->input.tensors[2] = const_tensor[55]; /* data_bias */

    /* MobilenetV1/Logits/SpatialSqueeze_4_acuity_mark_perm_11 */
    node[30]->input.tensors[0] = node[29]->output.tensors[0];

    /* MobilenetV1/Logits/SpatialSqueeze_4 */
    node[31]->input.tensors[0] = node[30]->output.tensors[0];

    /* MobilenetV1/Predictions/Softmax_2 */
    node[32]->input.tensors[0] = node[31]->output.tensors[0];


    graph->output.tensors[0] = norm_tensor[0];
    graph->input.tensors[0] = norm_tensor[1];


    if( enable_pre_post_process )
    {
        sort = TRUE;
        if( pre_process_map_count > 0 )
        {
            for( i = 0; i < pre_process_map_count; i++ )
            {
                status = vsi_nn_AddGraphPreProcess(graph, pre_process_map[i].graph_input_idx,
                                                   pre_process_map[i].preprocesses,
                                                   pre_process_map[i].preprocess_count);
                TEST_CHECK_STATUS( status, error );
            }
        }

        if( post_process_map_count > 0 )
        {
            for( i = 0; i < post_process_map_count; i++ )
            {
                 status = vsi_nn_AddGraphPostProcess(graph, post_process_map[i].graph_output_idx,
                                                     post_process_map[i].postprocesses,
                                                     post_process_map[i].postprocess_count);
                 TEST_CHECK_STATUS( status, error );
            }
        }
    }

    status = vsi_nn_SetupGraph( graph, sort );
    TEST_CHECK_STATUS( status, error );


    if( VSI_FAILURE == status )
    {
        goto error;
    }

    fclose( fp );

    return graph;

error:
    if( NULL != fp )
    {
        fclose( fp );
    }

    release_ctx = ( NULL == in_ctx );
    vsi_nn_DumpGraphToJson( graph );
    vnn_ReleaseMobilenetTf( graph, release_ctx );

    return NULL;
} /* vsi_nn_CreateMobilenetTf() */

void vnn_ReleaseMobilenetTf
    (
    vsi_nn_graph_t * graph,
    vsi_bool release_ctx
    )
{
    vsi_nn_context_t ctx;
    if( NULL != graph )
    {
        ctx = graph->ctx;
        vsi_nn_ReleaseGraph( &graph );

        /*-----------------------------------------
        Unregister client ops
        -----------------------------------------*/
        

        if( release_ctx )
        {
            vsi_nn_ReleaseContext( &ctx );
        }
    }
} /* vsi_nn_ReleaseMobilenetTf() */

